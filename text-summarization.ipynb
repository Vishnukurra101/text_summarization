{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-19T10:31:26.214106Z",
     "iopub.status.busy": "2024-11-19T10:31:26.213511Z",
     "iopub.status.idle": "2024-11-19T10:31:39.339631Z",
     "shell.execute_reply": "2024-11-19T10:31:39.338077Z",
     "shell.execute_reply.started": "2024-11-19T10:31:26.214057Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.46.3-py3-none-any.whl.metadata (44 kB)\n",
      "     ---------------------------------------- 0.0/44.1 kB ? eta -:--:--\n",
      "     -------------------------- ----------- 30.7/44.1 kB 640.0 kB/s eta 0:00:01\n",
      "     ----------------------------------- -- 41.0/44.1 kB 653.6 kB/s eta 0:00:01\n",
      "     -------------------------------------- 44.1/44.1 kB 360.6 kB/s eta 0:00:00\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting filelock (from transformers)\n",
      "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers)\n",
      "  Downloading huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\vishn\\onedrive\\desktop\\gui\\creategui\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\vishn\\onedrive\\desktop\\gui\\creategui\\lib\\site-packages (from transformers) (23.2)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Downloading PyYAML-6.0.2-cp311-cp311-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp311-cp311-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/41.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 41.5/41.5 kB 2.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests in c:\\users\\vishn\\onedrive\\desktop\\gui\\creategui\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers)\n",
      "  Downloading tokenizers-0.20.3-cp311-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.5-cp311-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Downloading tqdm-4.67.0-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 0.0/57.6 kB ? eta -:--:--\n",
      "     ----------------------------------- ---- 51.2/57.6 kB 2.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- 57.6/57.6 kB 764.4 kB/s eta 0:00:00\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-18.0.0-cp311-cp311-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\vishn\\onedrive\\desktop\\gui\\creategui\\lib\\site-packages (from datasets) (2.2.1)\n",
      "Collecting requests (from transformers)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.11.7-cp311-cp311-win_amd64.whl.metadata (8.0 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets)\n",
      "  Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\vishn\\onedrive\\desktop\\gui\\creategui\\lib\\site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Downloading frozenlist-1.5.0-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Downloading multidict-6.1.0-cp311-cp311-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->datasets)\n",
      "  Downloading propcache-0.2.0-cp311-cp311-win_amd64.whl.metadata (7.9 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.18.0-cp311-cp311-win_amd64.whl.metadata (69 kB)\n",
      "     ---------------------------------------- 0.0/69.9 kB ? eta -:--:--\n",
      "     ----- ---------------------------------- 10.2/69.9 kB ? eta -:--:--\n",
      "     ---------------- --------------------- 30.7/69.9 kB 640.0 kB/s eta 0:00:01\n",
      "     --------------------------------- ---- 61.4/69.9 kB 544.7 kB/s eta 0:00:01\n",
      "     -------------------------------------- 69.9/69.9 kB 423.5 kB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\vishn\\onedrive\\desktop\\gui\\creategui\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vishn\\onedrive\\desktop\\gui\\creategui\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vishn\\onedrive\\desktop\\gui\\creategui\\lib\\site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vishn\\onedrive\\desktop\\gui\\creategui\\lib\\site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vishn\\onedrive\\desktop\\gui\\creategui\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\vishn\\onedrive\\desktop\\gui\\creategui\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\vishn\\onedrive\\desktop\\gui\\creategui\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\vishn\\onedrive\\desktop\\gui\\creategui\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\vishn\\onedrive\\desktop\\gui\\creategui\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\vishn\\onedrive\\desktop\\gui\\creategui\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading transformers-4.46.3-py3-none-any.whl (10.0 MB)\n",
      "   ---------------------------------------- 0.0/10.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.0 MB 991.0 kB/s eta 0:00:11\n",
      "   ---------------------------------------- 0.1/10.0 MB 1.2 MB/s eta 0:00:09\n",
      "   ---------------------------------------- 0.1/10.0 MB 819.2 kB/s eta 0:00:13\n",
      "   ---------------------------------------- 0.1/10.0 MB 819.2 kB/s eta 0:00:13\n",
      "   ---------------------------------------- 0.1/10.0 MB 602.4 kB/s eta 0:00:17\n",
      "    --------------------------------------- 0.1/10.0 MB 532.5 kB/s eta 0:00:19\n",
      "    --------------------------------------- 0.1/10.0 MB 532.5 kB/s eta 0:00:19\n",
      "    --------------------------------------- 0.1/10.0 MB 532.5 kB/s eta 0:00:19\n",
      "    --------------------------------------- 0.2/10.0 MB 378.3 kB/s eta 0:00:27\n",
      "    --------------------------------------- 0.2/10.0 MB 378.3 kB/s eta 0:00:27\n",
      "    --------------------------------------- 0.2/10.0 MB 378.3 kB/s eta 0:00:27\n",
      "   - -------------------------------------- 0.3/10.0 MB 450.1 kB/s eta 0:00:22\n",
      "   - -------------------------------------- 0.3/10.0 MB 521.2 kB/s eta 0:00:19\n",
      "   - -------------------------------------- 0.4/10.0 MB 544.0 kB/s eta 0:00:18\n",
      "   - -------------------------------------- 0.4/10.0 MB 551.5 kB/s eta 0:00:18\n",
      "   - -------------------------------------- 0.4/10.0 MB 544.1 kB/s eta 0:00:18\n",
      "   - -------------------------------------- 0.4/10.0 MB 540.3 kB/s eta 0:00:18\n",
      "   - -------------------------------------- 0.5/10.0 MB 542.3 kB/s eta 0:00:18\n",
      "   - -------------------------------------- 0.5/10.0 MB 550.0 kB/s eta 0:00:18\n",
      "   -- ------------------------------------- 0.5/10.0 MB 546.4 kB/s eta 0:00:18\n",
      "   -- ------------------------------------- 0.5/10.0 MB 548.0 kB/s eta 0:00:18\n",
      "   -- ------------------------------------- 0.6/10.0 MB 554.9 kB/s eta 0:00:18\n",
      "   -- ------------------------------------- 0.6/10.0 MB 559.2 kB/s eta 0:00:17\n",
      "   -- ------------------------------------- 0.6/10.0 MB 544.8 kB/s eta 0:00:18\n",
      "   -- ------------------------------------- 0.7/10.0 MB 558.1 kB/s eta 0:00:17\n",
      "   -- ------------------------------------- 0.7/10.0 MB 554.9 kB/s eta 0:00:17\n",
      "   -- ------------------------------------- 0.7/10.0 MB 556.0 kB/s eta 0:00:17\n",
      "   -- ------------------------------------- 0.7/10.0 MB 561.0 kB/s eta 0:00:17\n",
      "   -- ------------------------------------- 0.7/10.0 MB 555.2 kB/s eta 0:00:17\n",
      "   --- ------------------------------------ 0.8/10.0 MB 552.5 kB/s eta 0:00:17\n",
      "   --- ------------------------------------ 0.8/10.0 MB 560.8 kB/s eta 0:00:17\n",
      "   --- ------------------------------------ 0.8/10.0 MB 560.8 kB/s eta 0:00:17\n",
      "   --- ------------------------------------ 0.8/10.0 MB 560.8 kB/s eta 0:00:17\n",
      "   --- ------------------------------------ 0.9/10.0 MB 551.6 kB/s eta 0:00:17\n",
      "   --- ------------------------------------ 0.9/10.0 MB 559.2 kB/s eta 0:00:17\n",
      "   --- ------------------------------------ 0.9/10.0 MB 556.5 kB/s eta 0:00:17\n",
      "   --- ------------------------------------ 1.0/10.0 MB 554.3 kB/s eta 0:00:17\n",
      "   --- ------------------------------------ 1.0/10.0 MB 555.9 kB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 1.0/10.0 MB 558.8 kB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 1.0/10.0 MB 556.3 kB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 1.1/10.0 MB 558.7 kB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 1.1/10.0 MB 561.0 kB/s eta 0:00:16\n",
      "   ---- ----------------------------------- 1.1/10.0 MB 563.2 kB/s eta 0:00:16\n",
      "   ---- ----------------------------------- 1.2/10.0 MB 565.6 kB/s eta 0:00:16\n",
      "   ---- ----------------------------------- 1.2/10.0 MB 566.7 kB/s eta 0:00:16\n",
      "   ---- ----------------------------------- 1.2/10.0 MB 568.6 kB/s eta 0:00:16\n",
      "   ---- ----------------------------------- 1.2/10.0 MB 566.5 kB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 1.3/10.0 MB 573.0 kB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 1.3/10.0 MB 574.6 kB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 1.4/10.0 MB 576.2 kB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 1.4/10.0 MB 577.8 kB/s eta 0:00:15\n",
      "   ----- ---------------------------------- 1.4/10.0 MB 579.5 kB/s eta 0:00:15\n",
      "   ----- ---------------------------------- 1.5/10.0 MB 585.0 kB/s eta 0:00:15\n",
      "   ----- ---------------------------------- 1.5/10.0 MB 586.3 kB/s eta 0:00:15\n",
      "   ------ --------------------------------- 1.5/10.0 MB 587.5 kB/s eta 0:00:15\n",
      "   ------ --------------------------------- 1.5/10.0 MB 588.7 kB/s eta 0:00:15\n",
      "   ------ --------------------------------- 1.6/10.0 MB 589.9 kB/s eta 0:00:15\n",
      "   ------ --------------------------------- 1.6/10.0 MB 602.8 kB/s eta 0:00:14\n",
      "   ------ --------------------------------- 1.7/10.0 MB 607.0 kB/s eta 0:00:14\n",
      "   ------ --------------------------------- 1.7/10.0 MB 608.0 kB/s eta 0:00:14\n",
      "   ------- -------------------------------- 1.8/10.0 MB 615.9 kB/s eta 0:00:14\n",
      "   ------- -------------------------------- 1.8/10.0 MB 616.5 kB/s eta 0:00:14\n",
      "   ------- -------------------------------- 1.8/10.0 MB 624.1 kB/s eta 0:00:14\n",
      "   ------- -------------------------------- 1.9/10.0 MB 631.4 kB/s eta 0:00:13\n",
      "   ------- -------------------------------- 2.0/10.0 MB 641.9 kB/s eta 0:00:13\n",
      "   -------- ------------------------------- 2.0/10.0 MB 658.7 kB/s eta 0:00:13\n",
      "   -------- ------------------------------- 2.1/10.0 MB 678.3 kB/s eta 0:00:12\n",
      "   -------- ------------------------------- 2.2/10.0 MB 687.8 kB/s eta 0:00:12\n",
      "   -------- ------------------------------- 2.2/10.0 MB 693.7 kB/s eta 0:00:12\n",
      "   --------- ------------------------------ 2.3/10.0 MB 702.5 kB/s eta 0:00:12\n",
      "   --------- ------------------------------ 2.4/10.0 MB 708.0 kB/s eta 0:00:11\n",
      "   --------- ------------------------------ 2.4/10.0 MB 708.0 kB/s eta 0:00:11\n",
      "   --------- ------------------------------ 2.4/10.0 MB 708.0 kB/s eta 0:00:11\n",
      "   --------- ------------------------------ 2.4/10.0 MB 694.2 kB/s eta 0:00:12\n",
      "   --------- ------------------------------ 2.5/10.0 MB 711.3 kB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 2.6/10.0 MB 739.5 kB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 2.6/10.0 MB 739.5 kB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 2.6/10.0 MB 739.5 kB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 2.7/10.0 MB 722.6 kB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 2.7/10.0 MB 722.6 kB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 2.7/10.0 MB 722.6 kB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 2.9/10.0 MB 758.0 kB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 2.9/10.0 MB 758.0 kB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 3.0/10.0 MB 754.7 kB/s eta 0:00:10\n",
      "   ------------ --------------------------- 3.0/10.0 MB 761.3 kB/s eta 0:00:10\n",
      "   ------------ --------------------------- 3.1/10.0 MB 760.3 kB/s eta 0:00:10\n",
      "   ------------ --------------------------- 3.1/10.0 MB 760.3 kB/s eta 0:00:10\n",
      "   ------------ --------------------------- 3.1/10.0 MB 760.3 kB/s eta 0:00:10\n",
      "   ------------ --------------------------- 3.3/10.0 MB 784.1 kB/s eta 0:00:09\n",
      "   ------------- -------------------------- 3.3/10.0 MB 784.5 kB/s eta 0:00:09\n",
      "   ------------- -------------------------- 3.3/10.0 MB 784.1 kB/s eta 0:00:09\n",
      "   ------------- -------------------------- 3.3/10.0 MB 784.1 kB/s eta 0:00:09\n",
      "   ------------- -------------------------- 3.3/10.0 MB 784.1 kB/s eta 0:00:09\n",
      "   ------------- -------------------------- 3.5/10.0 MB 794.0 kB/s eta 0:00:09\n",
      "   ------------- -------------------------- 3.5/10.0 MB 794.0 kB/s eta 0:00:09\n",
      "   -------------- ------------------------- 3.7/10.0 MB 829.0 kB/s eta 0:00:08\n",
      "   --------------- ------------------------ 3.8/10.0 MB 834.6 kB/s eta 0:00:08\n",
      "   --------------- ------------------------ 3.8/10.0 MB 837.2 kB/s eta 0:00:08\n",
      "   --------------- ------------------------ 3.9/10.0 MB 839.1 kB/s eta 0:00:08\n",
      "   --------------- ------------------------ 3.9/10.0 MB 841.8 kB/s eta 0:00:08\n",
      "   --------------- ------------------------ 4.0/10.0 MB 846.5 kB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 4.1/10.0 MB 848.9 kB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 4.1/10.0 MB 851.2 kB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 4.2/10.0 MB 853.5 kB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 4.2/10.0 MB 857.9 kB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 4.3/10.0 MB 860.1 kB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 4.3/10.0 MB 865.0 kB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 4.4/10.0 MB 868.6 kB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 4.4/10.0 MB 868.6 kB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 4.5/10.0 MB 872.6 kB/s eta 0:00:07\n",
      "   ------------------ --------------------- 4.5/10.0 MB 877.3 kB/s eta 0:00:07\n",
      "   ------------------ --------------------- 4.6/10.0 MB 879.2 kB/s eta 0:00:07\n",
      "   ------------------ --------------------- 4.7/10.0 MB 880.3 kB/s eta 0:00:07\n",
      "   ------------------ --------------------- 4.7/10.0 MB 884.8 kB/s eta 0:00:07\n",
      "   ------------------- -------------------- 4.8/10.0 MB 885.9 kB/s eta 0:00:06\n",
      "   ------------------- -------------------- 4.8/10.0 MB 890.3 kB/s eta 0:00:06\n",
      "   ------------------- -------------------- 4.9/10.0 MB 891.4 kB/s eta 0:00:06\n",
      "   ------------------- -------------------- 4.9/10.0 MB 895.5 kB/s eta 0:00:06\n",
      "   ------------------- -------------------- 5.0/10.0 MB 896.6 kB/s eta 0:00:06\n",
      "   -------------------- ------------------- 5.0/10.0 MB 899.0 kB/s eta 0:00:06\n",
      "   -------------------- ------------------- 5.1/10.0 MB 901.6 kB/s eta 0:00:06\n",
      "   -------------------- ------------------- 5.2/10.0 MB 903.2 kB/s eta 0:00:06\n",
      "   -------------------- ------------------- 5.2/10.0 MB 905.4 kB/s eta 0:00:06\n",
      "   -------------------- ------------------- 5.3/10.0 MB 906.3 kB/s eta 0:00:06\n",
      "   --------------------- ------------------ 5.3/10.0 MB 910.9 kB/s eta 0:00:06\n",
      "   --------------------- ------------------ 5.3/10.0 MB 906.3 kB/s eta 0:00:06\n",
      "   --------------------- ------------------ 5.4/10.0 MB 905.1 kB/s eta 0:00:06\n",
      "   --------------------- ------------------ 5.4/10.0 MB 905.1 kB/s eta 0:00:06\n",
      "   --------------------- ------------------ 5.4/10.0 MB 905.1 kB/s eta 0:00:06\n",
      "   --------------------- ------------------ 5.4/10.0 MB 891.9 kB/s eta 0:00:06\n",
      "   --------------------- ------------------ 5.4/10.0 MB 890.1 kB/s eta 0:00:06\n",
      "   --------------------- ------------------ 5.5/10.0 MB 893.9 kB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 5.5/10.0 MB 894.9 kB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 5.5/10.0 MB 894.9 kB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 5.5/10.0 MB 894.9 kB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 5.5/10.0 MB 894.9 kB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 5.5/10.0 MB 894.9 kB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 5.5/10.0 MB 894.9 kB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 5.5/10.0 MB 894.9 kB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 5.6/10.0 MB 853.5 kB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 5.7/10.0 MB 866.1 kB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 5.7/10.0 MB 866.1 kB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 5.7/10.0 MB 861.5 kB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 5.8/10.0 MB 858.6 kB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 5.8/10.0 MB 861.2 kB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 5.8/10.0 MB 859.8 kB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 5.9/10.0 MB 855.4 kB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 5.9/10.0 MB 863.9 kB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 6.0/10.0 MB 855.7 kB/s eta 0:00:05\n",
      "   ------------------------ --------------- 6.1/10.0 MB 870.0 kB/s eta 0:00:05\n",
      "   ------------------------ --------------- 6.2/10.0 MB 877.8 kB/s eta 0:00:05\n",
      "   ------------------------ --------------- 6.2/10.0 MB 878.2 kB/s eta 0:00:05\n",
      "   ------------------------- -------------- 6.3/10.0 MB 877.7 kB/s eta 0:00:05\n",
      "   ------------------------- -------------- 6.3/10.0 MB 878.2 kB/s eta 0:00:05\n",
      "   ------------------------- -------------- 6.3/10.0 MB 876.7 kB/s eta 0:00:05\n",
      "   ------------------------- -------------- 6.4/10.0 MB 876.2 kB/s eta 0:00:05\n",
      "   ------------------------- -------------- 6.4/10.0 MB 876.7 kB/s eta 0:00:05\n",
      "   ------------------------- -------------- 6.5/10.0 MB 875.2 kB/s eta 0:00:05\n",
      "   ------------------------- -------------- 6.5/10.0 MB 876.6 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 6.5/10.0 MB 877.1 kB/s eta 0:00:04\n",
      "   -------------------------- ------------- 6.6/10.0 MB 876.5 kB/s eta 0:00:04\n",
      "   -------------------------- ------------- 6.6/10.0 MB 876.1 kB/s eta 0:00:04\n",
      "   -------------------------- ------------- 6.7/10.0 MB 876.6 kB/s eta 0:00:04\n",
      "   -------------------------- ------------- 6.7/10.0 MB 876.1 kB/s eta 0:00:04\n",
      "   -------------------------- ------------- 6.7/10.0 MB 876.5 kB/s eta 0:00:04\n",
      "   --------------------------- ------------ 6.8/10.0 MB 876.0 kB/s eta 0:00:04\n",
      "   --------------------------- ------------ 6.8/10.0 MB 876.5 kB/s eta 0:00:04\n",
      "   --------------------------- ------------ 6.9/10.0 MB 876.9 kB/s eta 0:00:04\n",
      "   --------------------------- ------------ 6.9/10.0 MB 876.4 kB/s eta 0:00:04\n",
      "   --------------------------- ------------ 6.9/10.0 MB 876.9 kB/s eta 0:00:04\n",
      "   --------------------------- ------------ 7.0/10.0 MB 876.5 kB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 7.0/10.0 MB 875.2 kB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 7.1/10.0 MB 876.4 kB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 7.1/10.0 MB 877.6 kB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 7.2/10.0 MB 876.4 kB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 7.2/10.0 MB 877.6 kB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 7.2/10.0 MB 876.3 kB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 7.3/10.0 MB 877.6 kB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 7.3/10.0 MB 877.9 kB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 7.4/10.0 MB 877.5 kB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 7.4/10.0 MB 877.5 kB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 7.5/10.0 MB 879.1 kB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 7.5/10.0 MB 877.4 kB/s eta 0:00:03\n",
      "   ------------------------------ --------- 7.5/10.0 MB 878.6 kB/s eta 0:00:03\n",
      "   ------------------------------ --------- 7.6/10.0 MB 878.6 kB/s eta 0:00:03\n",
      "   ------------------------------ --------- 7.6/10.0 MB 879.0 kB/s eta 0:00:03\n",
      "   ------------------------------ --------- 7.7/10.0 MB 878.6 kB/s eta 0:00:03\n",
      "   ------------------------------ --------- 7.7/10.0 MB 879.7 kB/s eta 0:00:03\n",
      "   ------------------------------ --------- 7.8/10.0 MB 880.8 kB/s eta 0:00:03\n",
      "   ------------------------------- -------- 7.8/10.0 MB 881.2 kB/s eta 0:00:03\n",
      "   ------------------------------- -------- 7.9/10.0 MB 880.7 kB/s eta 0:00:03\n",
      "   ------------------------------- -------- 7.9/10.0 MB 881.8 kB/s eta 0:00:03\n",
      "   ------------------------------- -------- 7.9/10.0 MB 882.2 kB/s eta 0:00:03\n",
      "   ------------------------------- -------- 8.0/10.0 MB 883.3 kB/s eta 0:00:03\n",
      "   -------------------------------- ------- 8.0/10.0 MB 884.0 kB/s eta 0:00:03\n",
      "   -------------------------------- ------- 8.1/10.0 MB 884.3 kB/s eta 0:00:03\n",
      "   -------------------------------- ------- 8.1/10.0 MB 883.9 kB/s eta 0:00:03\n",
      "   -------------------------------- ------- 8.2/10.0 MB 884.3 kB/s eta 0:00:03\n",
      "   -------------------------------- ------- 8.2/10.0 MB 885.3 kB/s eta 0:00:03\n",
      "   -------------------------------- ------- 8.3/10.0 MB 884.8 kB/s eta 0:00:03\n",
      "   --------------------------------- ------ 8.3/10.0 MB 885.2 kB/s eta 0:00:02\n",
      "   --------------------------------- ------ 8.3/10.0 MB 886.2 kB/s eta 0:00:02\n",
      "   --------------------------------- ------ 8.4/10.0 MB 886.1 kB/s eta 0:00:02\n",
      "   --------------------------------- ------ 8.4/10.0 MB 887.1 kB/s eta 0:00:02\n",
      "   --------------------------------- ------ 8.5/10.0 MB 887.1 kB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 8.5/10.0 MB 888.1 kB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 8.6/10.0 MB 887.6 kB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 8.6/10.0 MB 888.6 kB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 8.7/10.0 MB 888.9 kB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 8.7/10.0 MB 889.9 kB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 8.8/10.0 MB 889.5 kB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 8.8/10.0 MB 890.4 kB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 8.8/10.0 MB 890.7 kB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 8.9/10.0 MB 891.7 kB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 8.9/10.0 MB 891.6 kB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 9.0/10.0 MB 891.1 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 9.0/10.0 MB 892.0 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 9.1/10.0 MB 892.3 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 9.1/10.0 MB 893.2 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 9.2/10.0 MB 894.1 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.2/10.0 MB 893.7 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.3/10.0 MB 893.6 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.3/10.0 MB 894.9 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.3/10.0 MB 894.8 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.4/10.0 MB 895.7 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.5/10.0 MB 896.5 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.5/10.0 MB 897.4 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.5/10.0 MB 897.3 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.6/10.0 MB 898.2 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.6/10.0 MB 899.0 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.7/10.0 MB 899.9 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.7/10.0 MB 900.7 kB/s eta 0:00:01\n",
      "   ---------------------------------------  9.8/10.0 MB 900.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------  9.8/10.0 MB 901.4 kB/s eta 0:00:01\n",
      "   ---------------------------------------  9.9/10.0 MB 902.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  9.9/10.0 MB 903.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  10.0/10.0 MB 903.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------  10.0/10.0 MB 904.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  10.0/10.0 MB 904.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.0/10.0 MB 898.6 kB/s eta 0:00:00\n",
      "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
      "   ---------------------------------------- 0.0/480.6 kB ? eta -:--:--\n",
      "   --- ----------------------------------- 41.0/480.6 kB 960.0 kB/s eta 0:00:01\n",
      "   --------- ------------------------------ 112.6/480.6 kB 1.3 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 163.8/480.6 kB 1.2 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 194.6/480.6 kB 1.1 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 245.8/480.6 kB 1.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 276.5/480.6 kB 1.0 MB/s eta 0:00:01\n",
      "   ---------------------- --------------- 286.7/480.6 kB 980.4 kB/s eta 0:00:01\n",
      "   ---------------------- --------------- 286.7/480.6 kB 980.4 kB/s eta 0:00:01\n",
      "   ------------------------- ------------ 327.7/480.6 kB 811.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 460.8/480.6 kB 994.6 kB/s eta 0:00:01\n",
      "   -------------------------------------  471.0/480.6 kB 982.5 kB/s eta 0:00:01\n",
      "   -------------------------------------- 480.6/480.6 kB 911.5 kB/s eta 0:00:00\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "   ---------------------------------------- 0.0/116.3 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 10.2/116.3 kB ? eta -:--:--\n",
      "   -------------------- ------------------ 61.4/116.3 kB 812.7 kB/s eta 0:00:01\n",
      "   ------------------------------ -------- 92.2/116.3 kB 871.5 kB/s eta 0:00:01\n",
      "   -------------------------------------- 116.3/116.3 kB 848.1 kB/s eta 0:00:00\n",
      "Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "   ---------------------------------------- 0.0/179.3 kB ? eta -:--:--\n",
      "   ------ -------------------------------- 30.7/179.3 kB 660.6 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 61.4/179.3 kB 812.7 kB/s eta 0:00:01\n",
      "   --------------------- ---------------- 102.4/179.3 kB 737.3 kB/s eta 0:00:01\n",
      "   -------------------------- ----------- 122.9/179.3 kB 798.9 kB/s eta 0:00:01\n",
      "   ------------------------------ ------- 143.4/179.3 kB 607.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 174.1/179.3 kB 697.2 kB/s eta 0:00:01\n",
      "   -------------------------------------- 179.3/179.3 kB 601.5 kB/s eta 0:00:00\n",
      "Downloading aiohttp-3.11.7-cp311-cp311-win_amd64.whl (440 kB)\n",
      "   ---------------------------------------- 0.0/440.9 kB ? eta -:--:--\n",
      "   -- ------------------------------------ 30.7/440.9 kB 660.6 kB/s eta 0:00:01\n",
      "   ----- --------------------------------- 61.4/440.9 kB 825.8 kB/s eta 0:00:01\n",
      "   -------- ------------------------------ 92.2/440.9 kB 751.6 kB/s eta 0:00:01\n",
      "   -------- ------------------------------ 92.2/440.9 kB 751.6 kB/s eta 0:00:01\n",
      "   -------- ------------------------------ 92.2/440.9 kB 751.6 kB/s eta 0:00:01\n",
      "   ------------- ------------------------ 153.6/440.9 kB 541.0 kB/s eta 0:00:01\n",
      "   --------------- ---------------------- 184.3/440.9 kB 619.5 kB/s eta 0:00:01\n",
      "   -------------------- ----------------- 235.5/440.9 kB 656.8 kB/s eta 0:00:01\n",
      "   ------------------------ ------------- 286.7/440.9 kB 681.0 kB/s eta 0:00:01\n",
      "   ----------------------------- -------- 337.9/440.9 kB 778.3 kB/s eta 0:00:01\n",
      "   ------------------------------- ------ 368.6/440.9 kB 740.5 kB/s eta 0:00:01\n",
      "   ---------------------------------- --- 399.4/440.9 kB 732.8 kB/s eta 0:00:01\n",
      "   ---------------------------------- --- 399.4/440.9 kB 732.8 kB/s eta 0:00:01\n",
      "   -------------------------------------  440.3/440.9 kB 706.2 kB/s eta 0:00:01\n",
      "   -------------------------------------- 440.9/440.9 kB 656.6 kB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
      "   ---------------------------------------- 0.0/447.5 kB ? eta -:--:--\n",
      "   -- ------------------------------------- 30.7/447.5 kB 1.3 MB/s eta 0:00:01\n",
      "   --- ----------------------------------- 41.0/447.5 kB 487.6 kB/s eta 0:00:01\n",
      "   ----- --------------------------------- 61.4/447.5 kB 544.7 kB/s eta 0:00:01\n",
      "   ------- ------------------------------- 81.9/447.5 kB 456.6 kB/s eta 0:00:01\n",
      "   ------- ------------------------------- 81.9/447.5 kB 456.6 kB/s eta 0:00:01\n",
      "   ------- ------------------------------- 81.9/447.5 kB 456.6 kB/s eta 0:00:01\n",
      "   -------- ------------------------------ 92.2/447.5 kB 275.8 kB/s eta 0:00:02\n",
      "   -------- ------------------------------ 92.2/447.5 kB 275.8 kB/s eta 0:00:02\n",
      "   -------- ------------------------------ 92.2/447.5 kB 275.8 kB/s eta 0:00:02\n",
      "   --------- ---------------------------- 112.6/447.5 kB 242.7 kB/s eta 0:00:02\n",
      "   ------------ ------------------------- 143.4/447.5 kB 274.5 kB/s eta 0:00:02\n",
      "   -------------- ----------------------- 174.1/447.5 kB 317.5 kB/s eta 0:00:01\n",
      "   ----------------- -------------------- 204.8/447.5 kB 345.6 kB/s eta 0:00:01\n",
      "   -------------------- ----------------- 245.8/447.5 kB 376.8 kB/s eta 0:00:01\n",
      "   ------------------------ ------------- 286.7/447.5 kB 401.9 kB/s eta 0:00:01\n",
      "   -------------------------- ----------- 317.4/447.5 kB 427.3 kB/s eta 0:00:01\n",
      "   ----------------------------- -------- 348.2/447.5 kB 441.1 kB/s eta 0:00:01\n",
      "   -------------------------------- ----- 378.9/447.5 kB 453.4 kB/s eta 0:00:01\n",
      "   ---------------------------------- --- 409.6/447.5 kB 464.4 kB/s eta 0:00:01\n",
      "   ---------------------------------- --- 409.6/447.5 kB 464.4 kB/s eta 0:00:01\n",
      "   -------------------------------------  440.3/447.5 kB 458.5 kB/s eta 0:00:01\n",
      "   -------------------------------------- 447.5/447.5 kB 451.3 kB/s eta 0:00:00\n",
      "Downloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "   ---------------------------------------- 0.0/143.5 kB ? eta -:--:--\n",
      "   ----- ---------------------------------- 20.5/143.5 kB ? eta -:--:--\n",
      "   -------- ------------------------------ 30.7/143.5 kB 640.0 kB/s eta 0:00:01\n",
      "   ------------------- ------------------- 71.7/143.5 kB 777.7 kB/s eta 0:00:01\n",
      "   --------------------------- ---------- 102.4/143.5 kB 653.6 kB/s eta 0:00:01\n",
      "   ----------------------------------- -- 133.1/143.5 kB 653.6 kB/s eta 0:00:01\n",
      "   -------------------------------------  143.4/143.5 kB 652.5 kB/s eta 0:00:01\n",
      "   -------------------------------------- 143.5/143.5 kB 533.1 kB/s eta 0:00:00\n",
      "Downloading pyarrow-18.0.0-cp311-cp311-win_amd64.whl (25.1 MB)\n",
      "   ---------------------------------------- 0.0/25.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/25.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/25.1 MB 495.5 kB/s eta 0:00:51\n",
      "   ---------------------------------------- 0.1/25.1 MB 563.7 kB/s eta 0:00:45\n",
      "   ---------------------------------------- 0.1/25.1 MB 585.1 kB/s eta 0:00:43\n",
      "   ---------------------------------------- 0.1/25.1 MB 602.4 kB/s eta 0:00:42\n",
      "   ---------------------------------------- 0.2/25.1 MB 612.6 kB/s eta 0:00:41\n",
      "   ---------------------------------------- 0.2/25.1 MB 655.9 kB/s eta 0:00:38\n",
      "   ---------------------------------------- 0.2/25.1 MB 655.6 kB/s eta 0:00:38\n",
      "   ---------------------------------------- 0.3/25.1 MB 682.7 kB/s eta 0:00:37\n",
      "    --------------------------------------- 0.3/25.1 MB 729.7 kB/s eta 0:00:34\n",
      "    --------------------------------------- 0.4/25.1 MB 765.8 kB/s eta 0:00:33\n",
      "    --------------------------------------- 0.4/25.1 MB 795.3 kB/s eta 0:00:32\n",
      "    --------------------------------------- 0.5/25.1 MB 783.5 kB/s eta 0:00:32\n",
      "    --------------------------------------- 0.5/25.1 MB 786.4 kB/s eta 0:00:32\n",
      "    --------------------------------------- 0.6/25.1 MB 808.8 kB/s eta 0:00:31\n",
      "    --------------------------------------- 0.6/25.1 MB 841.4 kB/s eta 0:00:30\n",
      "   - -------------------------------------- 0.7/25.1 MB 883.5 kB/s eta 0:00:28\n",
      "   - -------------------------------------- 0.8/25.1 MB 933.2 kB/s eta 0:00:27\n",
      "   - -------------------------------------- 0.8/25.1 MB 947.5 kB/s eta 0:00:26\n",
      "   - -------------------------------------- 0.9/25.1 MB 960.7 kB/s eta 0:00:26\n",
      "   - -------------------------------------- 0.9/25.1 MB 983.6 kB/s eta 0:00:25\n",
      "   - -------------------------------------- 1.0/25.1 MB 978.2 kB/s eta 0:00:25\n",
      "   - -------------------------------------- 1.0/25.1 MB 988.8 kB/s eta 0:00:25\n",
      "   - -------------------------------------- 1.0/25.1 MB 988.8 kB/s eta 0:00:25\n",
      "   - -------------------------------------- 1.0/25.1 MB 988.8 kB/s eta 0:00:25\n",
      "   - -------------------------------------- 1.2/25.1 MB 979.4 kB/s eta 0:00:25\n",
      "   - -------------------------------------- 1.2/25.1 MB 979.4 kB/s eta 0:00:25\n",
      "   -- ------------------------------------- 1.3/25.1 MB 1.0 MB/s eta 0:00:24\n",
      "   -- ------------------------------------- 1.3/25.1 MB 1.0 MB/s eta 0:00:24\n",
      "   -- ------------------------------------- 1.3/25.1 MB 956.9 kB/s eta 0:00:25\n",
      "   -- ------------------------------------- 1.4/25.1 MB 1.0 MB/s eta 0:00:24\n",
      "   -- ------------------------------------- 1.4/25.1 MB 1.0 MB/s eta 0:00:24\n",
      "   -- ------------------------------------- 1.5/25.1 MB 973.3 kB/s eta 0:00:25\n",
      "   -- ------------------------------------- 1.5/25.1 MB 983.2 kB/s eta 0:00:24\n",
      "   -- ------------------------------------- 1.5/25.1 MB 983.2 kB/s eta 0:00:24\n",
      "   -- ------------------------------------- 1.5/25.1 MB 983.2 kB/s eta 0:00:24\n",
      "   -- ------------------------------------- 1.5/25.1 MB 983.2 kB/s eta 0:00:24\n",
      "   -- ------------------------------------- 1.5/25.1 MB 983.2 kB/s eta 0:00:24\n",
      "   -- ------------------------------------- 1.8/25.1 MB 983.2 kB/s eta 0:00:24\n",
      "   -- ------------------------------------- 1.8/25.1 MB 983.2 kB/s eta 0:00:24\n",
      "   -- ------------------------------------- 1.8/25.1 MB 955.7 kB/s eta 0:00:25\n",
      "   --- ------------------------------------ 1.9/25.1 MB 1.0 MB/s eta 0:00:24\n",
      "   --- ------------------------------------ 1.9/25.1 MB 1.0 MB/s eta 0:00:24\n",
      "   --- ------------------------------------ 2.0/25.1 MB 983.2 kB/s eta 0:00:24\n",
      "   --- ------------------------------------ 2.0/25.1 MB 1.0 MB/s eta 0:00:23\n",
      "   --- ------------------------------------ 2.1/25.1 MB 985.6 kB/s eta 0:00:24\n",
      "   --- ------------------------------------ 2.3/25.1 MB 1.1 MB/s eta 0:00:22\n",
      "   --- ------------------------------------ 2.4/25.1 MB 1.1 MB/s eta 0:00:21\n",
      "   --- ------------------------------------ 2.5/25.1 MB 1.1 MB/s eta 0:00:21\n",
      "   ---- ----------------------------------- 2.5/25.1 MB 1.1 MB/s eta 0:00:21\n",
      "   ---- ----------------------------------- 2.6/25.1 MB 1.1 MB/s eta 0:00:21\n",
      "   ---- ----------------------------------- 2.6/25.1 MB 1.1 MB/s eta 0:00:21\n",
      "   ---- ----------------------------------- 2.7/25.1 MB 1.1 MB/s eta 0:00:21\n",
      "   ---- ----------------------------------- 2.7/25.1 MB 1.1 MB/s eta 0:00:21\n",
      "   ---- ----------------------------------- 2.8/25.1 MB 1.1 MB/s eta 0:00:21\n",
      "   ---- ----------------------------------- 2.8/25.1 MB 1.1 MB/s eta 0:00:21\n",
      "   ---- ----------------------------------- 2.9/25.1 MB 1.1 MB/s eta 0:00:21\n",
      "   ---- ----------------------------------- 3.0/25.1 MB 1.1 MB/s eta 0:00:21\n",
      "   ---- ----------------------------------- 3.0/25.1 MB 1.1 MB/s eta 0:00:20\n",
      "   ---- ----------------------------------- 3.1/25.1 MB 1.1 MB/s eta 0:00:20\n",
      "   ---- ----------------------------------- 3.1/25.1 MB 1.1 MB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 3.2/25.1 MB 1.1 MB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 3.2/25.1 MB 1.1 MB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 3.3/25.1 MB 1.1 MB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 3.3/25.1 MB 1.1 MB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 3.4/25.1 MB 1.1 MB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 3.5/25.1 MB 1.1 MB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 3.5/25.1 MB 1.1 MB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 3.6/25.1 MB 1.1 MB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 3.6/25.1 MB 1.1 MB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 3.7/25.1 MB 1.1 MB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 3.7/25.1 MB 1.1 MB/s eta 0:00:20\n",
      "   ------ --------------------------------- 3.8/25.1 MB 1.1 MB/s eta 0:00:20\n",
      "   ------ --------------------------------- 3.8/25.1 MB 1.1 MB/s eta 0:00:19\n",
      "   ------ --------------------------------- 3.9/25.1 MB 1.1 MB/s eta 0:00:19\n",
      "   ------ --------------------------------- 4.0/25.1 MB 1.1 MB/s eta 0:00:19\n",
      "   ------ --------------------------------- 4.0/25.1 MB 1.1 MB/s eta 0:00:19\n",
      "   ------ --------------------------------- 4.1/25.1 MB 1.1 MB/s eta 0:00:19\n",
      "   ------ --------------------------------- 4.1/25.1 MB 1.1 MB/s eta 0:00:19\n",
      "   ------ --------------------------------- 4.2/25.1 MB 1.1 MB/s eta 0:00:19\n",
      "   ------ --------------------------------- 4.2/25.1 MB 1.1 MB/s eta 0:00:19\n",
      "   ------ --------------------------------- 4.3/25.1 MB 1.1 MB/s eta 0:00:19\n",
      "   ------ --------------------------------- 4.3/25.1 MB 1.1 MB/s eta 0:00:19\n",
      "   ------ --------------------------------- 4.4/25.1 MB 1.1 MB/s eta 0:00:19\n",
      "   ------- -------------------------------- 4.5/25.1 MB 1.1 MB/s eta 0:00:19\n",
      "   ------- -------------------------------- 4.5/25.1 MB 1.1 MB/s eta 0:00:19\n",
      "   ------- -------------------------------- 4.5/25.1 MB 1.1 MB/s eta 0:00:19\n",
      "   ------- -------------------------------- 4.6/25.1 MB 1.1 MB/s eta 0:00:19\n",
      "   ------- -------------------------------- 4.7/25.1 MB 1.1 MB/s eta 0:00:19\n",
      "   ------- -------------------------------- 4.7/25.1 MB 1.1 MB/s eta 0:00:19\n",
      "   ------- -------------------------------- 4.8/25.1 MB 1.1 MB/s eta 0:00:18\n",
      "   ------- -------------------------------- 4.8/25.1 MB 1.1 MB/s eta 0:00:18\n",
      "   ------- -------------------------------- 4.9/25.1 MB 1.1 MB/s eta 0:00:18\n",
      "   ------- -------------------------------- 4.9/25.1 MB 1.1 MB/s eta 0:00:18\n",
      "   ------- -------------------------------- 5.0/25.1 MB 1.1 MB/s eta 0:00:18\n",
      "   -------- ------------------------------- 5.0/25.1 MB 1.1 MB/s eta 0:00:18\n",
      "   -------- ------------------------------- 5.1/25.1 MB 1.1 MB/s eta 0:00:18\n",
      "   -------- ------------------------------- 5.2/25.1 MB 1.1 MB/s eta 0:00:18\n",
      "   -------- ------------------------------- 5.2/25.1 MB 1.1 MB/s eta 0:00:18\n",
      "   -------- ------------------------------- 5.3/25.1 MB 1.1 MB/s eta 0:00:18\n",
      "   -------- ------------------------------- 5.3/25.1 MB 1.1 MB/s eta 0:00:18\n",
      "   -------- ------------------------------- 5.4/25.1 MB 1.1 MB/s eta 0:00:18\n",
      "   -------- ------------------------------- 5.4/25.1 MB 1.1 MB/s eta 0:00:18\n",
      "   -------- ------------------------------- 5.5/25.1 MB 1.1 MB/s eta 0:00:18\n",
      "   -------- ------------------------------- 5.5/25.1 MB 1.1 MB/s eta 0:00:18\n",
      "   -------- ------------------------------- 5.6/25.1 MB 1.1 MB/s eta 0:00:18\n",
      "   --------- ------------------------------ 5.7/25.1 MB 1.1 MB/s eta 0:00:18\n",
      "   --------- ------------------------------ 5.7/25.1 MB 1.1 MB/s eta 0:00:18\n",
      "   --------- ------------------------------ 5.8/25.1 MB 1.1 MB/s eta 0:00:17\n",
      "   --------- ------------------------------ 5.8/25.1 MB 1.1 MB/s eta 0:00:17\n",
      "   --------- ------------------------------ 5.9/25.1 MB 1.1 MB/s eta 0:00:17\n",
      "   --------- ------------------------------ 5.9/25.1 MB 1.1 MB/s eta 0:00:17\n",
      "   --------- ------------------------------ 6.0/25.1 MB 1.1 MB/s eta 0:00:17\n",
      "   --------- ------------------------------ 6.0/25.1 MB 1.1 MB/s eta 0:00:17\n",
      "   --------- ------------------------------ 6.1/25.1 MB 1.1 MB/s eta 0:00:17\n",
      "   --------- ------------------------------ 6.1/25.1 MB 1.1 MB/s eta 0:00:17\n",
      "   --------- ------------------------------ 6.2/25.1 MB 1.1 MB/s eta 0:00:17\n",
      "   --------- ------------------------------ 6.3/25.1 MB 1.1 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 6.3/25.1 MB 1.1 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 6.4/25.1 MB 1.1 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 6.4/25.1 MB 1.1 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 6.5/25.1 MB 1.1 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 6.5/25.1 MB 1.1 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 6.6/25.1 MB 1.1 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 6.6/25.1 MB 1.1 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 6.7/25.1 MB 1.1 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 6.7/25.1 MB 1.1 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 6.8/25.1 MB 1.1 MB/s eta 0:00:16\n",
      "   ---------- ----------------------------- 6.9/25.1 MB 1.1 MB/s eta 0:00:16\n",
      "   ----------- ---------------------------- 6.9/25.1 MB 1.1 MB/s eta 0:00:16\n",
      "   ----------- ---------------------------- 7.0/25.1 MB 1.1 MB/s eta 0:00:16\n",
      "   ----------- ---------------------------- 7.0/25.1 MB 1.1 MB/s eta 0:00:16\n",
      "   ----------- ---------------------------- 7.1/25.1 MB 1.1 MB/s eta 0:00:16\n",
      "   ----------- ---------------------------- 7.1/25.1 MB 1.1 MB/s eta 0:00:16\n",
      "   ----------- ---------------------------- 7.2/25.1 MB 1.1 MB/s eta 0:00:16\n",
      "   ----------- ---------------------------- 7.2/25.1 MB 1.1 MB/s eta 0:00:16\n",
      "   ----------- ---------------------------- 7.3/25.1 MB 1.1 MB/s eta 0:00:16\n",
      "   ----------- ---------------------------- 7.4/25.1 MB 1.1 MB/s eta 0:00:16\n",
      "   ----------- ---------------------------- 7.4/25.1 MB 1.1 MB/s eta 0:00:16\n",
      "   ----------- ---------------------------- 7.5/25.1 MB 1.1 MB/s eta 0:00:16\n",
      "   ----------- ---------------------------- 7.5/25.1 MB 1.1 MB/s eta 0:00:16\n",
      "   ------------ --------------------------- 7.6/25.1 MB 1.1 MB/s eta 0:00:16\n",
      "   ------------ --------------------------- 7.6/25.1 MB 1.1 MB/s eta 0:00:16\n",
      "   ------------ --------------------------- 7.7/25.1 MB 1.1 MB/s eta 0:00:16\n",
      "   ------------ --------------------------- 7.7/25.1 MB 1.1 MB/s eta 0:00:16\n",
      "   ------------ --------------------------- 7.8/25.1 MB 1.2 MB/s eta 0:00:16\n",
      "   ------------ --------------------------- 7.8/25.1 MB 1.1 MB/s eta 0:00:16\n",
      "   ------------ --------------------------- 7.9/25.1 MB 1.2 MB/s eta 0:00:15\n",
      "   ------------ --------------------------- 8.0/25.1 MB 1.2 MB/s eta 0:00:15\n",
      "   ------------ --------------------------- 8.0/25.1 MB 1.1 MB/s eta 0:00:15\n",
      "   ------------ --------------------------- 8.1/25.1 MB 1.2 MB/s eta 0:00:15\n",
      "   ------------ --------------------------- 8.1/25.1 MB 1.2 MB/s eta 0:00:15\n",
      "   ------------- -------------------------- 8.2/25.1 MB 1.1 MB/s eta 0:00:15\n",
      "   ------------- -------------------------- 8.2/25.1 MB 1.2 MB/s eta 0:00:15\n",
      "   ------------- -------------------------- 8.3/25.1 MB 1.2 MB/s eta 0:00:15\n",
      "   ------------- -------------------------- 8.4/25.1 MB 1.2 MB/s eta 0:00:15\n",
      "   ------------- -------------------------- 8.4/25.1 MB 1.2 MB/s eta 0:00:15\n",
      "   ------------- -------------------------- 8.5/25.1 MB 1.2 MB/s eta 0:00:15\n",
      "   ------------- -------------------------- 8.5/25.1 MB 1.2 MB/s eta 0:00:15\n",
      "   ------------- -------------------------- 8.6/25.1 MB 1.2 MB/s eta 0:00:15\n",
      "   ------------- -------------------------- 8.6/25.1 MB 1.2 MB/s eta 0:00:15\n",
      "   ------------- -------------------------- 8.7/25.1 MB 1.2 MB/s eta 0:00:15\n",
      "   ------------- -------------------------- 8.7/25.1 MB 1.2 MB/s eta 0:00:15\n",
      "   ------------- -------------------------- 8.8/25.1 MB 1.2 MB/s eta 0:00:15\n",
      "   -------------- ------------------------- 8.8/25.1 MB 1.2 MB/s eta 0:00:15\n",
      "   -------------- ------------------------- 8.9/25.1 MB 1.2 MB/s eta 0:00:15\n",
      "   -------------- ------------------------- 9.0/25.1 MB 1.2 MB/s eta 0:00:15\n",
      "   -------------- ------------------------- 9.0/25.1 MB 1.2 MB/s eta 0:00:14\n",
      "   -------------- ------------------------- 9.1/25.1 MB 1.2 MB/s eta 0:00:14\n",
      "   -------------- ------------------------- 9.1/25.1 MB 1.2 MB/s eta 0:00:14\n",
      "   -------------- ------------------------- 9.2/25.1 MB 1.2 MB/s eta 0:00:14\n",
      "   -------------- ------------------------- 9.2/25.1 MB 1.2 MB/s eta 0:00:14\n",
      "   -------------- ------------------------- 9.3/25.1 MB 1.2 MB/s eta 0:00:14\n",
      "   -------------- ------------------------- 9.3/25.1 MB 1.2 MB/s eta 0:00:14\n",
      "   -------------- ------------------------- 9.4/25.1 MB 1.2 MB/s eta 0:00:14\n",
      "   --------------- ------------------------ 9.4/25.1 MB 1.2 MB/s eta 0:00:14\n",
      "   --------------- ------------------------ 9.5/25.1 MB 1.2 MB/s eta 0:00:14\n",
      "   --------------- ------------------------ 9.6/25.1 MB 1.2 MB/s eta 0:00:14\n",
      "   --------------- ------------------------ 9.6/25.1 MB 1.2 MB/s eta 0:00:14\n",
      "   --------------- ------------------------ 9.7/25.1 MB 1.2 MB/s eta 0:00:14\n",
      "   --------------- ------------------------ 9.7/25.1 MB 1.2 MB/s eta 0:00:14\n",
      "   --------------- ------------------------ 9.8/25.1 MB 1.2 MB/s eta 0:00:14\n",
      "   --------------- ------------------------ 9.8/25.1 MB 1.2 MB/s eta 0:00:14\n",
      "   --------------- ------------------------ 9.9/25.1 MB 1.2 MB/s eta 0:00:14\n",
      "   --------------- ------------------------ 9.9/25.1 MB 1.2 MB/s eta 0:00:14\n",
      "   --------------- ------------------------ 10.0/25.1 MB 1.2 MB/s eta 0:00:14\n",
      "   ---------------- ----------------------- 10.0/25.1 MB 1.2 MB/s eta 0:00:14\n",
      "   ---------------- ----------------------- 10.1/25.1 MB 1.2 MB/s eta 0:00:13\n",
      "   ---------------- ----------------------- 10.2/25.1 MB 1.2 MB/s eta 0:00:13\n",
      "   ---------------- ----------------------- 10.2/25.1 MB 1.2 MB/s eta 0:00:13\n",
      "   ---------------- ----------------------- 10.3/25.1 MB 1.2 MB/s eta 0:00:13\n",
      "   ---------------- ----------------------- 10.3/25.1 MB 1.2 MB/s eta 0:00:13\n",
      "   ---------------- ----------------------- 10.4/25.1 MB 1.2 MB/s eta 0:00:13\n",
      "   ---------------- ----------------------- 10.4/25.1 MB 1.2 MB/s eta 0:00:13\n",
      "   ---------------- ----------------------- 10.5/25.1 MB 1.2 MB/s eta 0:00:13\n",
      "   ---------------- ----------------------- 10.5/25.1 MB 1.2 MB/s eta 0:00:13\n",
      "   ---------------- ----------------------- 10.6/25.1 MB 1.2 MB/s eta 0:00:13\n",
      "   ---------------- ----------------------- 10.6/25.1 MB 1.2 MB/s eta 0:00:13\n",
      "   ----------------- ---------------------- 10.7/25.1 MB 1.2 MB/s eta 0:00:13\n",
      "   ----------------- ---------------------- 10.8/25.1 MB 1.2 MB/s eta 0:00:13\n",
      "   ----------------- ---------------------- 10.8/25.1 MB 1.2 MB/s eta 0:00:13\n",
      "   ----------------- ---------------------- 10.9/25.1 MB 1.2 MB/s eta 0:00:13\n",
      "   ----------------- ---------------------- 10.9/25.1 MB 1.2 MB/s eta 0:00:13\n",
      "   ----------------- ---------------------- 11.0/25.1 MB 1.2 MB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 11.0/25.1 MB 1.2 MB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 11.1/25.1 MB 1.2 MB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 11.1/25.1 MB 1.2 MB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 11.2/25.1 MB 1.2 MB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 11.2/25.1 MB 1.2 MB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 11.3/25.1 MB 1.2 MB/s eta 0:00:12\n",
      "   ------------------ --------------------- 11.4/25.1 MB 1.2 MB/s eta 0:00:12\n",
      "   ------------------ --------------------- 11.4/25.1 MB 1.2 MB/s eta 0:00:12\n",
      "   ------------------ --------------------- 11.5/25.1 MB 1.2 MB/s eta 0:00:12\n",
      "   ------------------ --------------------- 11.5/25.1 MB 1.2 MB/s eta 0:00:12\n",
      "   ------------------ --------------------- 11.6/25.1 MB 1.2 MB/s eta 0:00:12\n",
      "   ------------------ --------------------- 11.6/25.1 MB 1.2 MB/s eta 0:00:12\n",
      "   ------------------ --------------------- 11.7/25.1 MB 1.2 MB/s eta 0:00:12\n",
      "   ------------------ --------------------- 11.7/25.1 MB 1.2 MB/s eta 0:00:12\n",
      "   ------------------ --------------------- 11.8/25.1 MB 1.2 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 11.9/25.1 MB 1.2 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 11.9/25.1 MB 1.2 MB/s eta 0:00:11\n",
      "   ------------------- -------------------- 12.0/25.1 MB 1.2 MB/s eta 0:00:11\n",
      "   ------------------- -------------------- 12.0/25.1 MB 1.2 MB/s eta 0:00:11\n",
      "   ------------------- -------------------- 12.1/25.1 MB 1.2 MB/s eta 0:00:11\n",
      "   ------------------- -------------------- 12.1/25.1 MB 1.2 MB/s eta 0:00:11\n",
      "   ------------------- -------------------- 12.2/25.1 MB 1.2 MB/s eta 0:00:11\n",
      "   ------------------- -------------------- 12.2/25.1 MB 1.2 MB/s eta 0:00:11\n",
      "   ------------------- -------------------- 12.3/25.1 MB 1.2 MB/s eta 0:00:11\n",
      "   ------------------- -------------------- 12.3/25.1 MB 1.2 MB/s eta 0:00:11\n",
      "   ------------------- -------------------- 12.4/25.1 MB 1.2 MB/s eta 0:00:11\n",
      "   ------------------- -------------------- 12.5/25.1 MB 1.2 MB/s eta 0:00:11\n",
      "   ------------------- -------------------- 12.5/25.1 MB 1.2 MB/s eta 0:00:11\n",
      "   ------------------- -------------------- 12.5/25.1 MB 1.2 MB/s eta 0:00:11\n",
      "   ------------------- -------------------- 12.5/25.1 MB 1.2 MB/s eta 0:00:11\n",
      "   ------------------- -------------------- 12.5/25.1 MB 1.2 MB/s eta 0:00:11\n",
      "   -------------------- ------------------- 12.6/25.1 MB 1.2 MB/s eta 0:00:11\n",
      "   -------------------- ------------------- 12.6/25.1 MB 1.2 MB/s eta 0:00:11\n",
      "   -------------------- ------------------- 12.6/25.1 MB 1.2 MB/s eta 0:00:11\n",
      "   -------------------- ------------------- 12.7/25.1 MB 1.2 MB/s eta 0:00:11\n",
      "   -------------------- ------------------- 12.7/25.1 MB 1.2 MB/s eta 0:00:11\n",
      "   -------------------- ------------------- 12.8/25.1 MB 1.2 MB/s eta 0:00:11\n",
      "   -------------------- ------------------- 12.8/25.1 MB 1.2 MB/s eta 0:00:11\n",
      "   -------------------- ------------------- 12.9/25.1 MB 1.2 MB/s eta 0:00:11\n",
      "   -------------------- ------------------- 13.0/25.1 MB 1.2 MB/s eta 0:00:11\n",
      "   -------------------- ------------------- 13.1/25.1 MB 1.2 MB/s eta 0:00:11\n",
      "   -------------------- ------------------- 13.2/25.1 MB 1.2 MB/s eta 0:00:11\n",
      "   --------------------- ------------------ 13.2/25.1 MB 1.2 MB/s eta 0:00:11\n",
      "   --------------------- ------------------ 13.2/25.1 MB 1.2 MB/s eta 0:00:11\n",
      "   --------------------- ------------------ 13.2/25.1 MB 1.2 MB/s eta 0:00:11\n",
      "   --------------------- ------------------ 13.3/25.1 MB 1.1 MB/s eta 0:00:11\n",
      "   --------------------- ------------------ 13.3/25.1 MB 1.2 MB/s eta 0:00:11\n",
      "   --------------------- ------------------ 13.3/25.1 MB 1.2 MB/s eta 0:00:11\n",
      "   --------------------- ------------------ 13.5/25.1 MB 1.2 MB/s eta 0:00:10\n",
      "   --------------------- ------------------ 13.5/25.1 MB 1.2 MB/s eta 0:00:10\n",
      "   --------------------- ------------------ 13.5/25.1 MB 1.2 MB/s eta 0:00:10\n",
      "   --------------------- ------------------ 13.5/25.1 MB 1.2 MB/s eta 0:00:10\n",
      "   --------------------- ------------------ 13.5/25.1 MB 1.2 MB/s eta 0:00:10\n",
      "   --------------------- ------------------ 13.6/25.1 MB 1.1 MB/s eta 0:00:11\n",
      "   --------------------- ------------------ 13.6/25.1 MB 1.1 MB/s eta 0:00:11\n",
      "   --------------------- ------------------ 13.6/25.1 MB 1.1 MB/s eta 0:00:11\n",
      "   --------------------- ------------------ 13.6/25.1 MB 1.1 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 13.9/25.1 MB 1.1 MB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 13.9/25.1 MB 1.1 MB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 13.9/25.1 MB 1.1 MB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 13.9/25.1 MB 1.1 MB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 13.9/25.1 MB 1.1 MB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 13.9/25.1 MB 1.1 MB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 14.0/25.1 MB 1.1 MB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 14.1/25.1 MB 1.1 MB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 14.2/25.1 MB 1.1 MB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 14.5/25.1 MB 1.2 MB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 14.5/25.1 MB 1.2 MB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 14.6/25.1 MB 1.2 MB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 14.6/25.1 MB 1.2 MB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 14.7/25.1 MB 1.2 MB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 14.7/25.1 MB 1.2 MB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 14.8/25.1 MB 1.1 MB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 14.8/25.1 MB 1.2 MB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 14.9/25.1 MB 1.2 MB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 14.9/25.1 MB 1.2 MB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 15.0/25.1 MB 1.2 MB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 15.1/25.1 MB 1.2 MB/s eta 0:00:09\n",
      "   ------------------------ --------------- 15.1/25.1 MB 1.2 MB/s eta 0:00:09\n",
      "   ------------------------ --------------- 15.1/25.1 MB 1.2 MB/s eta 0:00:09\n",
      "   ------------------------ --------------- 15.2/25.1 MB 1.1 MB/s eta 0:00:09\n",
      "   ------------------------ --------------- 15.3/25.1 MB 1.2 MB/s eta 0:00:09\n",
      "   ------------------------ --------------- 15.3/25.1 MB 1.2 MB/s eta 0:00:09\n",
      "   ------------------------ --------------- 15.4/25.1 MB 1.1 MB/s eta 0:00:09\n",
      "   ------------------------ --------------- 15.4/25.1 MB 1.1 MB/s eta 0:00:09\n",
      "   ------------------------ --------------- 15.4/25.1 MB 1.1 MB/s eta 0:00:09\n",
      "   ------------------------ --------------- 15.4/25.1 MB 1.1 MB/s eta 0:00:09\n",
      "   ------------------------ --------------- 15.4/25.1 MB 1.1 MB/s eta 0:00:09\n",
      "   ------------------------ --------------- 15.5/25.1 MB 1.1 MB/s eta 0:00:09\n",
      "   ------------------------ --------------- 15.5/25.1 MB 1.1 MB/s eta 0:00:09\n",
      "   ------------------------ --------------- 15.6/25.1 MB 1.1 MB/s eta 0:00:09\n",
      "   ------------------------ --------------- 15.6/25.1 MB 1.1 MB/s eta 0:00:09\n",
      "   ------------------------ --------------- 15.7/25.1 MB 1.1 MB/s eta 0:00:09\n",
      "   ------------------------- -------------- 15.7/25.1 MB 1.1 MB/s eta 0:00:09\n",
      "   ------------------------- -------------- 15.8/25.1 MB 1.1 MB/s eta 0:00:09\n",
      "   ------------------------- -------------- 15.8/25.1 MB 1.1 MB/s eta 0:00:09\n",
      "   ------------------------- -------------- 15.9/25.1 MB 1.1 MB/s eta 0:00:09\n",
      "   ------------------------- -------------- 15.9/25.1 MB 1.1 MB/s eta 0:00:09\n",
      "   ------------------------- -------------- 15.9/25.1 MB 1.1 MB/s eta 0:00:09\n",
      "   ------------------------- -------------- 15.9/25.1 MB 1.1 MB/s eta 0:00:09\n",
      "   ------------------------- -------------- 15.9/25.1 MB 1.1 MB/s eta 0:00:09\n",
      "   ------------------------- -------------- 15.9/25.1 MB 1.1 MB/s eta 0:00:09\n",
      "   ------------------------- -------------- 15.9/25.1 MB 1.1 MB/s eta 0:00:09\n",
      "   ------------------------- -------------- 15.9/25.1 MB 1.1 MB/s eta 0:00:09\n",
      "   ------------------------- -------------- 15.9/25.1 MB 1.1 MB/s eta 0:00:09\n",
      "   ------------------------- -------------- 15.9/25.1 MB 1.1 MB/s eta 0:00:09\n",
      "   ------------------------- -------------- 16.0/25.1 MB 1.1 MB/s eta 0:00:09\n",
      "   ------------------------- -------------- 16.0/25.1 MB 1.1 MB/s eta 0:00:09\n",
      "   ------------------------- -------------- 16.3/25.1 MB 1.1 MB/s eta 0:00:09\n",
      "   ------------------------- -------------- 16.3/25.1 MB 1.1 MB/s eta 0:00:09\n",
      "   -------------------------- ------------- 16.3/25.1 MB 1.1 MB/s eta 0:00:08\n",
      "   -------------------------- ------------- 16.4/25.1 MB 1.1 MB/s eta 0:00:08\n",
      "   -------------------------- ------------- 16.5/25.1 MB 1.1 MB/s eta 0:00:08\n",
      "   -------------------------- ------------- 16.5/25.1 MB 1.1 MB/s eta 0:00:08\n",
      "   -------------------------- ------------- 16.5/25.1 MB 1.1 MB/s eta 0:00:08\n",
      "   -------------------------- ------------- 16.6/25.1 MB 1.1 MB/s eta 0:00:08\n",
      "   -------------------------- ------------- 16.6/25.1 MB 1.1 MB/s eta 0:00:08\n",
      "   -------------------------- ------------- 16.7/25.1 MB 1.1 MB/s eta 0:00:08\n",
      "   -------------------------- ------------- 16.8/25.1 MB 1.1 MB/s eta 0:00:08\n",
      "   -------------------------- ------------- 16.8/25.1 MB 1.1 MB/s eta 0:00:08\n",
      "   -------------------------- ------------- 16.9/25.1 MB 1.1 MB/s eta 0:00:08\n",
      "   -------------------------- ------------- 16.9/25.1 MB 1.1 MB/s eta 0:00:08\n",
      "   --------------------------- ------------ 17.0/25.1 MB 1.1 MB/s eta 0:00:08\n",
      "   --------------------------- ------------ 17.0/25.1 MB 1.1 MB/s eta 0:00:08\n",
      "   --------------------------- ------------ 17.1/25.1 MB 1.1 MB/s eta 0:00:08\n",
      "   --------------------------- ------------ 17.1/25.1 MB 1.1 MB/s eta 0:00:08\n",
      "   --------------------------- ------------ 17.2/25.1 MB 1.1 MB/s eta 0:00:08\n",
      "   --------------------------- ------------ 17.2/25.1 MB 1.1 MB/s eta 0:00:08\n",
      "   --------------------------- ------------ 17.2/25.1 MB 1.1 MB/s eta 0:00:08\n",
      "   --------------------------- ------------ 17.3/25.1 MB 1.1 MB/s eta 0:00:08\n",
      "   --------------------------- ------------ 17.3/25.1 MB 1.1 MB/s eta 0:00:08\n",
      "   --------------------------- ------------ 17.4/25.1 MB 1.1 MB/s eta 0:00:08\n",
      "   --------------------------- ------------ 17.4/25.1 MB 1.1 MB/s eta 0:00:08\n",
      "   --------------------------- ------------ 17.5/25.1 MB 1.1 MB/s eta 0:00:08\n",
      "   --------------------------- ------------ 17.6/25.1 MB 1.1 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 17.6/25.1 MB 1.1 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 17.7/25.1 MB 1.1 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 17.7/25.1 MB 1.1 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 17.8/25.1 MB 1.1 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 17.8/25.1 MB 1.1 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 17.9/25.1 MB 1.1 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 18.0/25.1 MB 1.1 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 18.0/25.1 MB 1.1 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 18.1/25.1 MB 1.1 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 18.1/25.1 MB 1.1 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 18.2/25.1 MB 1.1 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 18.2/25.1 MB 1.1 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 18.3/25.1 MB 1.1 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 18.3/25.1 MB 1.1 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 18.4/25.1 MB 1.1 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 18.4/25.1 MB 1.1 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 18.5/25.1 MB 1.1 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 18.5/25.1 MB 1.1 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 18.6/25.1 MB 1.1 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 18.6/25.1 MB 1.1 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 18.7/25.1 MB 1.1 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 18.8/25.1 MB 1.1 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 18.8/25.1 MB 1.1 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 18.9/25.1 MB 1.1 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 18.9/25.1 MB 1.1 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 19.0/25.1 MB 1.1 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 19.0/25.1 MB 1.1 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 19.1/25.1 MB 1.1 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 19.1/25.1 MB 1.1 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 19.2/25.1 MB 1.1 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 19.3/25.1 MB 1.1 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 19.3/25.1 MB 1.1 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 19.4/25.1 MB 1.1 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 19.4/25.1 MB 1.1 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 19.5/25.1 MB 1.1 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 19.5/25.1 MB 1.1 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 19.6/25.1 MB 1.1 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 19.6/25.1 MB 1.1 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 19.7/25.1 MB 1.1 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 19.7/25.1 MB 1.1 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 19.8/25.1 MB 1.1 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 19.9/25.1 MB 1.1 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 19.9/25.1 MB 1.1 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 20.0/25.1 MB 1.1 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 20.0/25.1 MB 1.1 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 20.1/25.1 MB 1.1 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 20.1/25.1 MB 1.1 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 20.2/25.1 MB 1.1 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 20.2/25.1 MB 1.1 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 20.3/25.1 MB 1.1 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 20.3/25.1 MB 1.1 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 20.4/25.1 MB 1.1 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 20.5/25.1 MB 1.1 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 20.5/25.1 MB 1.1 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 20.6/25.1 MB 1.1 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 20.6/25.1 MB 1.1 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 20.7/25.1 MB 1.1 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 20.7/25.1 MB 1.1 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 20.8/25.1 MB 1.1 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 20.8/25.1 MB 1.1 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 20.9/25.1 MB 1.1 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 21.0/25.1 MB 1.1 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 21.0/25.1 MB 1.1 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 21.1/25.1 MB 1.1 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 21.1/25.1 MB 1.1 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 21.2/25.1 MB 1.1 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 21.2/25.1 MB 1.1 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 21.3/25.1 MB 1.1 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 21.4/25.1 MB 1.1 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 21.4/25.1 MB 1.1 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 21.5/25.1 MB 1.1 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 21.5/25.1 MB 1.1 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 21.6/25.1 MB 1.1 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 21.6/25.1 MB 1.1 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 21.7/25.1 MB 1.1 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 21.7/25.1 MB 1.1 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 21.8/25.1 MB 1.1 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 21.8/25.1 MB 1.1 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 21.9/25.1 MB 1.1 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 21.9/25.1 MB 1.1 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 22.0/25.1 MB 1.1 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 22.1/25.1 MB 1.1 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 22.1/25.1 MB 1.1 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 22.2/25.1 MB 1.1 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 22.2/25.1 MB 1.1 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 22.3/25.1 MB 1.1 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 22.3/25.1 MB 1.1 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 22.4/25.1 MB 1.1 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 22.4/25.1 MB 1.1 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 22.5/25.1 MB 1.1 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 22.5/25.1 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 22.6/25.1 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 22.7/25.1 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 22.7/25.1 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 22.8/25.1 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 22.8/25.1 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 22.9/25.1 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 22.9/25.1 MB 1.1 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 23.0/25.1 MB 1.1 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 23.0/25.1 MB 1.1 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 23.1/25.1 MB 1.1 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 23.2/25.1 MB 1.1 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 23.2/25.1 MB 1.1 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 23.3/25.1 MB 1.1 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 23.3/25.1 MB 1.1 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 23.4/25.1 MB 1.1 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 23.4/25.1 MB 1.1 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 23.5/25.1 MB 1.1 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 23.5/25.1 MB 1.1 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 23.6/25.1 MB 1.1 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 23.7/25.1 MB 1.1 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 23.7/25.1 MB 1.1 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 23.8/25.1 MB 1.1 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 23.8/25.1 MB 1.1 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 23.8/25.1 MB 1.1 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 23.8/25.1 MB 1.1 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 23.8/25.1 MB 1.1 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 23.8/25.1 MB 1.1 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 23.9/25.1 MB 1.1 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 23.9/25.1 MB 1.1 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 24.0/25.1 MB 1.1 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 24.0/25.1 MB 1.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 24.1/25.1 MB 1.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 24.2/25.1 MB 1.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 24.2/25.1 MB 1.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 24.3/25.1 MB 1.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 24.4/25.1 MB 1.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 24.5/25.1 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.5/25.1 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.5/25.1 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.5/25.1 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.5/25.1 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.6/25.1 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.6/25.1 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.8/25.1 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.8/25.1 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.8/25.1 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.8/25.1 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.8/25.1 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  25.1/25.1 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  25.1/25.1 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  25.1/25.1 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.1/25.1 MB 1.1 MB/s eta 0:00:00\n",
      "Downloading PyYAML-6.0.2-cp311-cp311-win_amd64.whl (161 kB)\n",
      "   ---------------------------------------- 0.0/162.0 kB ? eta -:--:--\n",
      "   ------------------------------ --------- 122.9/162.0 kB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 162.0/162.0 kB 1.9 MB/s eta 0:00:00\n",
      "Downloading regex-2024.11.6-cp311-cp311-win_amd64.whl (274 kB)\n",
      "   ---------------------------------------- 0.0/274.1 kB ? eta -:--:--\n",
      "   ----------------- ---------------------- 122.9/274.1 kB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 194.6/274.1 kB 2.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 245.8/274.1 kB 1.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 266.2/274.1 kB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 274.1/274.1 kB 1.4 MB/s eta 0:00:00\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "   ---------------------------------------- 0.0/64.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 64.9/64.9 kB 1.8 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.4.5-cp311-none-win_amd64.whl (285 kB)\n",
      "   ---------------------------------------- 0.0/286.0 kB ? eta -:--:--\n",
      "   ----------------- ---------------------- 122.9/286.0 kB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 204.8/286.0 kB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 245.8/286.0 kB 1.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 276.5/286.0 kB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 286.0/286.0 kB 1.5 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.20.3-cp311-none-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.1/2.4 MB 4.3 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 0.2/2.4 MB 2.9 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 0.3/2.4 MB 2.0 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.3/2.4 MB 2.0 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.3/2.4 MB 2.0 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.3/2.4 MB 2.0 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.3/2.4 MB 1.1 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.3/2.4 MB 1.1 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.3/2.4 MB 1.1 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.3/2.4 MB 1.1 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.3/2.4 MB 1.1 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 0.4/2.4 MB 675.0 kB/s eta 0:00:03\n",
      "   ------ --------------------------------- 0.4/2.4 MB 675.0 kB/s eta 0:00:03\n",
      "   ------ --------------------------------- 0.4/2.4 MB 675.0 kB/s eta 0:00:03\n",
      "   --------- ------------------------------ 0.6/2.4 MB 853.3 kB/s eta 0:00:03\n",
      "   --------- ------------------------------ 0.6/2.4 MB 853.3 kB/s eta 0:00:03\n",
      "   --------- ------------------------------ 0.6/2.4 MB 853.3 kB/s eta 0:00:03\n",
      "   --------- ------------------------------ 0.6/2.4 MB 853.3 kB/s eta 0:00:03\n",
      "   --------- ------------------------------ 0.6/2.4 MB 853.3 kB/s eta 0:00:03\n",
      "   --------- ------------------------------ 0.6/2.4 MB 853.3 kB/s eta 0:00:03\n",
      "   --------- ------------------------------ 0.6/2.4 MB 853.3 kB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 0.7/2.4 MB 675.8 kB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 0.7/2.4 MB 675.8 kB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 0.7/2.4 MB 675.8 kB/s eta 0:00:03\n",
      "   ------------ --------------------------- 0.7/2.4 MB 637.8 kB/s eta 0:00:03\n",
      "   ------------ --------------------------- 0.7/2.4 MB 637.8 kB/s eta 0:00:03\n",
      "   --------------------- ------------------ 1.3/2.4 MB 1.0 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 1.5/2.4 MB 1.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.6/2.4 MB 1.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.6/2.4 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.7/2.4 MB 1.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.8/2.4 MB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.8/2.4 MB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.9/2.4 MB 1.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.9/2.4 MB 1.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 2.0/2.4 MB 1.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 2.0/2.4 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 2.1/2.4 MB 1.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 2.1/2.4 MB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 2.2/2.4 MB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.2/2.4 MB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.3/2.4 MB 1.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.3/2.4 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.4/2.4 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.4/2.4 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 1.1 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.67.0-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.6 kB ? eta -:--:--\n",
      "   -------------------- ------------------- 41.0/78.6 kB 991.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 78.6/78.6 kB 1.1 MB/s eta 0:00:00\n",
      "Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Downloading xxhash-3.5.0-cp311-cp311-win_amd64.whl (30 kB)\n",
      "Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.5.0-cp311-cp311-win_amd64.whl (51 kB)\n",
      "   ---------------------------------------- 0.0/51.6 kB ? eta -:--:--\n",
      "   ---------------------------------------  51.2/51.6 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 51.6/51.6 kB 880.7 kB/s eta 0:00:00\n",
      "Downloading multidict-6.1.0-cp311-cp311-win_amd64.whl (28 kB)\n",
      "Downloading propcache-0.2.0-cp311-cp311-win_amd64.whl (44 kB)\n",
      "   ---------------------------------------- 0.0/44.9 kB ? eta -:--:--\n",
      "   ------------------------------------ --- 41.0/44.9 kB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 44.9/44.9 kB 1.1 MB/s eta 0:00:00\n",
      "Downloading yarl-1.18.0-cp311-cp311-win_amd64.whl (90 kB)\n",
      "   ---------------------------------------- 0.0/90.8 kB ? eta -:--:--\n",
      "   ------------- -------------------------- 30.7/90.8 kB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 81.9/90.8 kB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 90.8/90.8 kB 732.0 kB/s eta 0:00:00\n",
      "Installing collected packages: xxhash, tqdm, safetensors, requests, regex, pyyaml, pyarrow, propcache, multidict, fsspec, frozenlist, filelock, dill, aiohappyeyeballs, yarl, multiprocess, huggingface-hub, aiosignal, tokenizers, aiohttp, transformers, datasets\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "Successfully installed aiohappyeyeballs-2.4.3 aiohttp-3.11.7 aiosignal-1.3.1 datasets-3.1.0 dill-0.3.8 filelock-3.16.1 frozenlist-1.5.0 fsspec-2024.9.0 huggingface-hub-0.26.2 multidict-6.1.0 multiprocess-0.70.16 propcache-0.2.0 pyarrow-18.0.0 pyyaml-6.0.2 regex-2024.11.6 requests-2.32.3 safetensors-0.4.5 tokenizers-0.20.3 tqdm-4.67.0 transformers-4.46.3 xxhash-3.5.0 yarl-1.18.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# pip install transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T10:31:39.343619Z",
     "iopub.status.busy": "2024-11-19T10:31:39.343099Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "\n",
    "# # Compute lengths\n",
    "# article_lengths = [len(article.split()) for article in dataset['train']['article']]\n",
    "# summary_lengths = [len(summary.split()) for summary in dataset['train']['highlights']]\n",
    "\n",
    "# # Plotting Article Lengths\n",
    "# plt.figure(figsize=(14, 6))\n",
    "# sns.histplot(article_lengths, bins=50, color='blue')\n",
    "# plt.title('Distribution of Article Lengths')\n",
    "# plt.xlabel('Number of Words')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.show()\n",
    "\n",
    "# # Plotting Summary Lengths\n",
    "# plt.figure(figsize=(14, 6))\n",
    "# sns.histplot(summary_lengths, bins=100, color='red')\n",
    "# plt.title('Distribution of Summary Lengths')\n",
    "# plt.xlabel('Number of Words')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# from wordcloud import WordCloud\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Join all summaries\n",
    "# text = \" \".join(summary for summary in dataset['train']['highlights'])\n",
    "\n",
    "# # Optionally, you can clean the text (remove stopwords, punctuation, etc.)\n",
    "# # For example:\n",
    "# # text = clean_text_function(text)\n",
    "\n",
    "# # Generate word cloud\n",
    "# wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
    "\n",
    "# # Plot the word cloud\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.imshow(wordcloud, interpolation='bilinear')\n",
    "# plt.axis('off')  # Disable axis\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'LABEL_0', '1': 'LABEL_1'}. The number of labels wil be overwritten to 2.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "\n",
    "tokenizer = BartTokenizer.from_pretrained('lucadiliello/bart-small')\n",
    "model = BartForConditionalGeneration.from_pretrained('lucadiliello/bart-small', ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    # Tokenize the articles and summaries (highlights)\n",
    "    inputs = tokenizer(examples['article'], padding='max_length', truncation=True, max_length=512)\n",
    "    labels = tokenizer(examples['highlights'], padding='max_length', truncation=True, max_length=150)\n",
    "\n",
    "    # Ensure that labels are correctly aligned with the input format\n",
    "    inputs['labels'] = labels['input_ids']\n",
    "    return inputs\n",
    "\n",
    "\n",
    "# Apply the preprocessing function to the dataset\n",
    "tokenized_datasets = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\vishn\\OneDrive\\Desktop\\GUI\\creategui\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(  \n",
    "    output_dir='./results',          \n",
    "    num_train_epochs=3,              \n",
    "    per_device_train_batch_size=4,  \n",
    "    per_device_eval_batch_size=4,   \n",
    "    warmup_steps=500,                \n",
    "    weight_decay=0.01,               \n",
    "    logging_dir='./logs',\n",
    "    report_to=\"none\",\n",
    "    save_steps=500,\n",
    "    save_total_limit=3, \n",
    "    remove_unused_columns=False,\n",
    "    load_best_model_at_end=True,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model.to('cuda:0'),\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['validation'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].\n",
      "c:\\Users\\vishn\\OneDrive\\Desktop\\GUI\\creategui\\Lib\\site-packages\\transformers\\trainer.py:3354: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(os.path.join(checkpoint, OPTIMIZER_NAME), map_location=map_location)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6a1ec6524db45baad5914d42a83170c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/215337 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vishn\\OneDrive\\Desktop\\GUI\\creategui\\Lib\\site-packages\\transformers\\trainer.py:3033: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint_rng_state = torch.load(rng_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9552, 'grad_norm': 3.4449682235717773, 'learning_rate': 9.387814948076914e-06, 'epoch': 2.44}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eabdb0326e243cb9013f426fd1c89c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.004974603652954, 'eval_runtime': 433.6607, 'eval_samples_per_second': 30.826, 'eval_steps_per_second': 7.706, 'epoch': 2.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vishn\\OneDrive\\Desktop\\GUI\\creategui\\Lib\\site-packages\\transformers\\modeling_utils.py:2817: UserWarning: Moving the following attributes in the config to the generation config: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9482, 'grad_norm': 3.161107063293457, 'learning_rate': 9.271447655664527e-06, 'epoch': 2.45}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99761288b1f74400adbcd686327e1f83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0057594776153564, 'eval_runtime': 430.6465, 'eval_samples_per_second': 31.042, 'eval_steps_per_second': 7.76, 'epoch': 2.45}\n",
      "{'loss': 0.946, 'grad_norm': 3.1007490158081055, 'learning_rate': 9.15508036325214e-06, 'epoch': 2.45}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a409264e61f4e8aa3fdd7a8178591d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0036935806274414, 'eval_runtime': 432.8351, 'eval_samples_per_second': 30.885, 'eval_steps_per_second': 7.721, 'epoch': 2.45}\n",
      "{'loss': 0.9466, 'grad_norm': 3.2495946884155273, 'learning_rate': 9.038713070839753e-06, 'epoch': 2.46}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da1806e8045846a2b42decf654326315",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.004141092300415, 'eval_runtime': 432.3593, 'eval_samples_per_second': 30.919, 'eval_steps_per_second': 7.73, 'epoch': 2.46}\n",
      "{'loss': 0.9409, 'grad_norm': 2.4113731384277344, 'learning_rate': 8.922345778427365e-06, 'epoch': 2.47}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "446e12cd52134c0c80c6d99023b551e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0029646158218384, 'eval_runtime': 433.1474, 'eval_samples_per_second': 30.862, 'eval_steps_per_second': 7.716, 'epoch': 2.47}\n",
      "{'loss': 0.9526, 'grad_norm': 3.340195894241333, 'learning_rate': 8.805978486014979e-06, 'epoch': 2.47}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33955ce7178b4aa79e745731471f6af3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0035316944122314, 'eval_runtime': 432.9393, 'eval_samples_per_second': 30.877, 'eval_steps_per_second': 7.719, 'epoch': 2.47}\n",
      "{'loss': 0.915, 'grad_norm': 3.2875728607177734, 'learning_rate': 8.689611193602593e-06, 'epoch': 2.48}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31f1a70af27f4c72a8ffeb8bf11a4731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0047632455825806, 'eval_runtime': 433.2013, 'eval_samples_per_second': 30.859, 'eval_steps_per_second': 7.715, 'epoch': 2.48}\n",
      "{'loss': 0.9416, 'grad_norm': 3.234811544418335, 'learning_rate': 8.573243901190205e-06, 'epoch': 2.49}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71826039fb0b4be4b309681ee2b14438",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.001027226448059, 'eval_runtime': 432.3918, 'eval_samples_per_second': 30.916, 'eval_steps_per_second': 7.729, 'epoch': 2.49}\n",
      "{'loss': 0.9417, 'grad_norm': 3.2226412296295166, 'learning_rate': 8.456876608777819e-06, 'epoch': 2.49}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef092c8a1d9445e183751f7035e42ce1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0018538236618042, 'eval_runtime': 432.9906, 'eval_samples_per_second': 30.874, 'eval_steps_per_second': 7.718, 'epoch': 2.49}\n",
      "{'loss': 0.935, 'grad_norm': 3.310758113861084, 'learning_rate': 8.340509316365432e-06, 'epoch': 2.5}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2503314b9d0b40f6959960cedbf42ea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9988282918930054, 'eval_runtime': 434.1507, 'eval_samples_per_second': 30.791, 'eval_steps_per_second': 7.698, 'epoch': 2.5}\n",
      "{'loss': 0.9522, 'grad_norm': 2.729060411453247, 'learning_rate': 8.224142023953044e-06, 'epoch': 2.51}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff0f69fca13e4f0989a75fad410222ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0010478496551514, 'eval_runtime': 434.75, 'eval_samples_per_second': 30.749, 'eval_steps_per_second': 7.687, 'epoch': 2.51}\n",
      "{'loss': 0.9499, 'grad_norm': 2.7315893173217773, 'learning_rate': 8.107774731540657e-06, 'epoch': 2.51}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dbe537180604c37a10fc8aa216369ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0007312297821045, 'eval_runtime': 431.9121, 'eval_samples_per_second': 30.951, 'eval_steps_per_second': 7.738, 'epoch': 2.51}\n",
      "{'loss': 0.9116, 'grad_norm': 2.9550223350524902, 'learning_rate': 7.991407439128269e-06, 'epoch': 2.52}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55cb56208fd54cfe89e953552b5ec695",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.000363826751709, 'eval_runtime': 433.404, 'eval_samples_per_second': 30.844, 'eval_steps_per_second': 7.711, 'epoch': 2.52}\n",
      "{'loss': 0.9414, 'grad_norm': 3.580775260925293, 'learning_rate': 7.875040146715882e-06, 'epoch': 2.53}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "789442fc04744620b7a1d7eacc80c52d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0031397342681885, 'eval_runtime': 432.8075, 'eval_samples_per_second': 30.887, 'eval_steps_per_second': 7.722, 'epoch': 2.53}\n",
      "{'loss': 0.9428, 'grad_norm': 3.2153546810150146, 'learning_rate': 7.758672854303496e-06, 'epoch': 2.54}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d52e7a8e5c2b4b0d8a87b84478bad81a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.002611756324768, 'eval_runtime': 485.136, 'eval_samples_per_second': 27.555, 'eval_steps_per_second': 6.889, 'epoch': 2.54}\n",
      "{'loss': 0.9295, 'grad_norm': 3.910555601119995, 'learning_rate': 7.642305561891108e-06, 'epoch': 2.54}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aa4a91983b9498bae231087de2b3c8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0007588863372803, 'eval_runtime': 601.9582, 'eval_samples_per_second': 22.208, 'eval_steps_per_second': 5.552, 'epoch': 2.54}\n",
      "{'loss': 0.924, 'grad_norm': 3.2114744186401367, 'learning_rate': 7.525938269478722e-06, 'epoch': 2.55}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04050c154a0449039c65ba7b0fc5a645",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.000340461730957, 'eval_runtime': 500.4131, 'eval_samples_per_second': 26.714, 'eval_steps_per_second': 6.678, 'epoch': 2.55}\n",
      "{'loss': 0.9541, 'grad_norm': 3.963820695877075, 'learning_rate': 7.409570977066334e-06, 'epoch': 2.56}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf4b0724596e4a0d81c1f36d3fdefbc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.002021312713623, 'eval_runtime': 434.4669, 'eval_samples_per_second': 30.769, 'eval_steps_per_second': 7.692, 'epoch': 2.56}\n",
      "{'loss': 0.95, 'grad_norm': 2.8678863048553467, 'learning_rate': 7.293203684653948e-06, 'epoch': 2.56}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f61e68167ea3454fb5995e63e32c41f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0029417276382446, 'eval_runtime': 434.3053, 'eval_samples_per_second': 30.78, 'eval_steps_per_second': 7.695, 'epoch': 2.56}\n",
      "{'loss': 0.951, 'grad_norm': 3.231208562850952, 'learning_rate': 7.176836392241561e-06, 'epoch': 2.57}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82ece9917431467f92bd66a1f677727c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.002819538116455, 'eval_runtime': 433.5532, 'eval_samples_per_second': 30.834, 'eval_steps_per_second': 7.708, 'epoch': 2.57}\n",
      "{'loss': 0.9523, 'grad_norm': 2.566392183303833, 'learning_rate': 7.060469099829173e-06, 'epoch': 2.58}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8e43153aef542fabfe9cdd56ffc52eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0006581544876099, 'eval_runtime': 433.7506, 'eval_samples_per_second': 30.82, 'eval_steps_per_second': 7.705, 'epoch': 2.58}\n",
      "{'loss': 0.9488, 'grad_norm': 3.4117379188537598, 'learning_rate': 6.944101807416786e-06, 'epoch': 2.58}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb9e373e63d840e1b8d4dde4d68215e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9986356496810913, 'eval_runtime': 433.6023, 'eval_samples_per_second': 30.83, 'eval_steps_per_second': 7.708, 'epoch': 2.58}\n",
      "{'loss': 0.9409, 'grad_norm': 2.7642862796783447, 'learning_rate': 6.8277345150043985e-06, 'epoch': 2.59}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d0da9d329064851864939a63bff89d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9984531998634338, 'eval_runtime': 435.1229, 'eval_samples_per_second': 30.722, 'eval_steps_per_second': 7.681, 'epoch': 2.59}\n",
      "{'loss': 0.9428, 'grad_norm': 2.793286085128784, 'learning_rate': 6.711367222592012e-06, 'epoch': 2.6}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c29e3088ccf749728b62b312e818ca53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0003249645233154, 'eval_runtime': 433.1422, 'eval_samples_per_second': 30.863, 'eval_steps_per_second': 7.716, 'epoch': 2.6}\n",
      "{'loss': 0.9505, 'grad_norm': 3.2047855854034424, 'learning_rate': 6.594999930179625e-06, 'epoch': 2.61}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0373d34c0e6e45edb66eaedb0a683502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.001159906387329, 'eval_runtime': 433.1703, 'eval_samples_per_second': 30.861, 'eval_steps_per_second': 7.715, 'epoch': 2.61}\n",
      "{'loss': 0.9249, 'grad_norm': 3.122647523880005, 'learning_rate': 6.478632637767237e-06, 'epoch': 2.61}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5226a7fc1019461f8242fffba647d775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9998785853385925, 'eval_runtime': 434.163, 'eval_samples_per_second': 30.79, 'eval_steps_per_second': 7.698, 'epoch': 2.61}\n",
      "{'loss': 0.9386, 'grad_norm': 2.9150218963623047, 'learning_rate': 6.362265345354851e-06, 'epoch': 2.62}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe681cd86ad4403d9691ecbb95ed31a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9993976354598999, 'eval_runtime': 434.6083, 'eval_samples_per_second': 30.759, 'eval_steps_per_second': 7.69, 'epoch': 2.62}\n",
      "{'loss': 0.9343, 'grad_norm': 3.107248067855835, 'learning_rate': 6.245898052942464e-06, 'epoch': 2.63}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9f68b40512342deb70e30446554d066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9979147911071777, 'eval_runtime': 433.3583, 'eval_samples_per_second': 30.847, 'eval_steps_per_second': 7.712, 'epoch': 2.63}\n",
      "{'loss': 0.9294, 'grad_norm': 2.8963065147399902, 'learning_rate': 6.129530760530077e-06, 'epoch': 2.63}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f51734eb4b241b29683bf7a3f45c9a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9969374537467957, 'eval_runtime': 433.5045, 'eval_samples_per_second': 30.837, 'eval_steps_per_second': 7.709, 'epoch': 2.63}\n",
      "{'loss': 0.947, 'grad_norm': 3.241466999053955, 'learning_rate': 6.013163468117689e-06, 'epoch': 2.64}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1d2bf5bce6a4de2a5123733d783df20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9983060359954834, 'eval_runtime': 433.503, 'eval_samples_per_second': 30.837, 'eval_steps_per_second': 7.709, 'epoch': 2.64}\n",
      "{'loss': 0.9452, 'grad_norm': 5.35836935043335, 'learning_rate': 5.8967961757053025e-06, 'epoch': 2.65}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13167f2ec7cc47ea901b0b1d6bb89736",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9993817806243896, 'eval_runtime': 433.6364, 'eval_samples_per_second': 30.828, 'eval_steps_per_second': 7.707, 'epoch': 2.65}\n",
      "{'loss': 0.9322, 'grad_norm': 3.503675699234009, 'learning_rate': 5.7804288832929154e-06, 'epoch': 2.65}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7480f78f05ae4982a2c5f56646776056",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9982695579528809, 'eval_runtime': 432.754, 'eval_samples_per_second': 30.891, 'eval_steps_per_second': 7.723, 'epoch': 2.65}\n",
      "{'loss': 0.9344, 'grad_norm': 3.1180384159088135, 'learning_rate': 5.664061590880528e-06, 'epoch': 2.66}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0575130281145e78a5a832f616eed75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9990664124488831, 'eval_runtime': 432.9843, 'eval_samples_per_second': 30.874, 'eval_steps_per_second': 7.719, 'epoch': 2.66}\n",
      "{'loss': 0.9433, 'grad_norm': 3.299849510192871, 'learning_rate': 5.547694298468141e-06, 'epoch': 2.67}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b6e0fda998b4cb7829bac3bb0109ce3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.998249351978302, 'eval_runtime': 433.6052, 'eval_samples_per_second': 30.83, 'eval_steps_per_second': 7.707, 'epoch': 2.67}\n",
      "{'loss': 0.9498, 'grad_norm': 3.4832003116607666, 'learning_rate': 5.431327006055754e-06, 'epoch': 2.67}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0ffb36eb7944e6a962a31e4b39e5da0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9974964261054993, 'eval_runtime': 433.8604, 'eval_samples_per_second': 30.812, 'eval_steps_per_second': 7.703, 'epoch': 2.67}\n",
      "{'loss': 0.9259, 'grad_norm': 2.722755193710327, 'learning_rate': 5.314959713643367e-06, 'epoch': 2.68}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bddf97dc1c54315bef1a44800ff1dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9979225397109985, 'eval_runtime': 433.7133, 'eval_samples_per_second': 30.822, 'eval_steps_per_second': 7.706, 'epoch': 2.68}\n",
      "{'loss': 0.9457, 'grad_norm': 3.490478992462158, 'learning_rate': 5.19859242123098e-06, 'epoch': 2.69}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53cbd10059624201b100f12b6c1d54ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9986381530761719, 'eval_runtime': 433.5728, 'eval_samples_per_second': 30.832, 'eval_steps_per_second': 7.708, 'epoch': 2.69}\n",
      "{'loss': 0.9523, 'grad_norm': 2.995920419692993, 'learning_rate': 5.082225128818593e-06, 'epoch': 2.7}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70be9518ba9546b882cfe7ba301ce2fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9982113838195801, 'eval_runtime': 434.3496, 'eval_samples_per_second': 30.777, 'eval_steps_per_second': 7.694, 'epoch': 2.7}\n",
      "{'loss': 0.9299, 'grad_norm': 3.228013515472412, 'learning_rate': 4.965857836406206e-06, 'epoch': 2.7}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a027cf13a2484dacac2419d79c534138",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9975340366363525, 'eval_runtime': 434.0251, 'eval_samples_per_second': 30.8, 'eval_steps_per_second': 7.7, 'epoch': 2.7}\n",
      "{'loss': 0.9508, 'grad_norm': 3.031545639038086, 'learning_rate': 4.849490543993819e-06, 'epoch': 2.71}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c687c97cca8d4d25b2b59c9d9efb7809",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9976454973220825, 'eval_runtime': 429.0208, 'eval_samples_per_second': 31.159, 'eval_steps_per_second': 7.79, 'epoch': 2.71}\n",
      "{'loss': 0.9375, 'grad_norm': 2.893324851989746, 'learning_rate': 4.733123251581432e-06, 'epoch': 2.72}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "968e244061f5440fb25b8f565b6c9a4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9963013529777527, 'eval_runtime': 438.2178, 'eval_samples_per_second': 30.505, 'eval_steps_per_second': 7.626, 'epoch': 2.72}\n",
      "{'loss': 0.9557, 'grad_norm': 3.8519721031188965, 'learning_rate': 4.6167559591690445e-06, 'epoch': 2.72}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f09f8ffe2291462ea2d106ffe2a8cec5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9951168298721313, 'eval_runtime': 439.6337, 'eval_samples_per_second': 30.407, 'eval_steps_per_second': 7.602, 'epoch': 2.72}\n",
      "{'loss': 0.9508, 'grad_norm': 3.20857310295105, 'learning_rate': 4.500388666756657e-06, 'epoch': 2.73}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec279c8f8b194b448a991d105142225b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9959677457809448, 'eval_runtime': 448.7967, 'eval_samples_per_second': 29.786, 'eval_steps_per_second': 7.447, 'epoch': 2.73}\n",
      "{'loss': 0.946, 'grad_norm': 2.7555971145629883, 'learning_rate': 4.384021374344271e-06, 'epoch': 2.74}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76cbfb2ad69047bd890c8fa5d1d3dabd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9964926242828369, 'eval_runtime': 436.3201, 'eval_samples_per_second': 30.638, 'eval_steps_per_second': 7.66, 'epoch': 2.74}\n",
      "{'loss': 0.9386, 'grad_norm': 3.397829532623291, 'learning_rate': 4.267654081931883e-06, 'epoch': 2.74}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6d707db613f4784895230d1893f3091",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9966801404953003, 'eval_runtime': 436.7812, 'eval_samples_per_second': 30.606, 'eval_steps_per_second': 7.651, 'epoch': 2.74}\n",
      "{'loss': 0.9368, 'grad_norm': 3.5739078521728516, 'learning_rate': 4.151286789519496e-06, 'epoch': 2.75}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "425ec906968b420d89cf20db2aca3c5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9946426153182983, 'eval_runtime': 436.9909, 'eval_samples_per_second': 30.591, 'eval_steps_per_second': 7.648, 'epoch': 2.75}\n",
      "{'loss': 0.9382, 'grad_norm': 3.125213861465454, 'learning_rate': 4.034919497107109e-06, 'epoch': 2.76}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4738f0a966c34b889ddc5c69af9a952f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9963277578353882, 'eval_runtime': 437.2261, 'eval_samples_per_second': 30.575, 'eval_steps_per_second': 7.644, 'epoch': 2.76}\n",
      "{'loss': 0.9431, 'grad_norm': 2.814892292022705, 'learning_rate': 3.918552204694722e-06, 'epoch': 2.77}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa368b2115cd4c629524b26d27399772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9949876070022583, 'eval_runtime': 437.2062, 'eval_samples_per_second': 30.576, 'eval_steps_per_second': 7.644, 'epoch': 2.77}\n",
      "{'loss': 0.9402, 'grad_norm': 2.997847318649292, 'learning_rate': 3.8021849122823352e-06, 'epoch': 2.77}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62e1803b22bf44c383b63aebfaccfeb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9959481358528137, 'eval_runtime': 436.6637, 'eval_samples_per_second': 30.614, 'eval_steps_per_second': 7.653, 'epoch': 2.77}\n",
      "{'loss': 0.9261, 'grad_norm': 2.7531239986419678, 'learning_rate': 3.685817619869948e-06, 'epoch': 2.78}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1927b94264bb43e586d6be0d1d9e67f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9942421913146973, 'eval_runtime': 436.6708, 'eval_samples_per_second': 30.613, 'eval_steps_per_second': 7.653, 'epoch': 2.78}\n",
      "{'loss': 0.9438, 'grad_norm': 3.47200608253479, 'learning_rate': 3.569450327457561e-06, 'epoch': 2.79}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b51e54e2c31c4c4bafc934829e4cace6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9952691197395325, 'eval_runtime': 436.3247, 'eval_samples_per_second': 30.638, 'eval_steps_per_second': 7.659, 'epoch': 2.79}\n",
      "{'loss': 0.9361, 'grad_norm': 3.785430431365967, 'learning_rate': 3.4530830350451735e-06, 'epoch': 2.79}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "741e49735aaf4ef68c7909f5983d3bd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9936178922653198, 'eval_runtime': 437.8607, 'eval_samples_per_second': 30.53, 'eval_steps_per_second': 7.633, 'epoch': 2.79}\n",
      "{'loss': 0.9331, 'grad_norm': 3.266632080078125, 'learning_rate': 3.3367157426327873e-06, 'epoch': 2.8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8f6906c365d45049e950ff6493d3c98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.994010329246521, 'eval_runtime': 436.4042, 'eval_samples_per_second': 30.632, 'eval_steps_per_second': 7.658, 'epoch': 2.8}\n",
      "{'loss': 0.927, 'grad_norm': 2.8474738597869873, 'learning_rate': 3.2203484502203998e-06, 'epoch': 2.81}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bcc9c29f4c04634a459c11cdf30f7cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vishn\\OneDrive\\Desktop\\GUI\\creategui\\Lib\\site-packages\\transformers\\trainer.py:2123\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   2121\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   2122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2124\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2128\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vishn\\OneDrive\\Desktop\\GUI\\creategui\\Lib\\site-packages\\transformers\\trainer.py:2548\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2546\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m epoch \u001b[38;5;241m+\u001b[39m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m steps_skipped) \u001b[38;5;241m/\u001b[39m steps_in_epoch\n\u001b[0;32m   2547\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m-> 2548\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2549\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2550\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_substep_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[1;32mc:\\Users\\vishn\\OneDrive\\Desktop\\GUI\\creategui\\Lib\\site-packages\\transformers\\trainer.py:3004\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[1;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   3002\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   3003\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_evaluate:\n\u001b[1;32m-> 3004\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3006\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[0;32m   3007\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_checkpoint(model, trial, metrics\u001b[38;5;241m=\u001b[39mmetrics)\n",
      "File \u001b[1;32mc:\\Users\\vishn\\OneDrive\\Desktop\\GUI\\creategui\\Lib\\site-packages\\transformers\\trainer.py:2958\u001b[0m, in \u001b[0;36mTrainer._evaluate\u001b[1;34m(self, trial, ignore_keys_for_eval, skip_scheduler)\u001b[0m\n\u001b[0;32m   2957\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_evaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, ignore_keys_for_eval, skip_scheduler\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m-> 2958\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2959\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step, metrics)\n\u001b[0;32m   2961\u001b[0m     \u001b[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\vishn\\OneDrive\\Desktop\\GUI\\creategui\\Lib\\site-packages\\transformers\\trainer.py:3975\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[1;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   3972\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m   3974\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[1;32m-> 3975\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3976\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3978\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[0;32m   3979\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[0;32m   3980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   3981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3983\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3985\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[0;32m   3986\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[1;32mc:\\Users\\vishn\\OneDrive\\Desktop\\GUI\\creategui\\Lib\\site-packages\\transformers\\trainer.py:4169\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[1;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   4166\u001b[0m         batch_size \u001b[38;5;241m=\u001b[39m observed_batch_size\n\u001b[0;32m   4168\u001b[0m \u001b[38;5;66;03m# Prediction step\u001b[39;00m\n\u001b[1;32m-> 4169\u001b[0m losses, logits, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4170\u001b[0m main_input_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain_input_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   4171\u001b[0m inputs_decode \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   4172\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_input(inputs[main_input_name]) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m args\u001b[38;5;241m.\u001b[39minclude_for_metrics \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   4173\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\vishn\\OneDrive\\Desktop\\GUI\\creategui\\Lib\\site-packages\\transformers\\trainer.py:4385\u001b[0m, in \u001b[0;36mTrainer.prediction_step\u001b[1;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[0m\n\u001b[0;32m   4383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_labels \u001b[38;5;129;01mor\u001b[39;00m loss_without_labels:\n\u001b[0;32m   4384\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[1;32m-> 4385\u001b[0m         loss, outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   4386\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[0;32m   4388\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\vishn\\OneDrive\\Desktop\\GUI\\creategui\\Lib\\site-packages\\transformers\\trainer.py:3633\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[1;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[0;32m   3631\u001b[0m         loss_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_items_in_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_items_in_batch\n\u001b[0;32m   3632\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mloss_kwargs}\n\u001b[1;32m-> 3633\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3634\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[0;32m   3635\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[0;32m   3636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\vishn\\OneDrive\\Desktop\\GUI\\creategui\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vishn\\OneDrive\\Desktop\\GUI\\creategui\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\vishn\\OneDrive\\Desktop\\GUI\\creategui\\Lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:1642\u001b[0m, in \u001b[0;36mBartForConditionalGeneration.forward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1637\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m decoder_input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m decoder_inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1638\u001b[0m         decoder_input_ids \u001b[38;5;241m=\u001b[39m shift_tokens_right(\n\u001b[0;32m   1639\u001b[0m             labels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpad_token_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdecoder_start_token_id\n\u001b[0;32m   1640\u001b[0m         )\n\u001b[1;32m-> 1642\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1643\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1648\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1650\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1651\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1652\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1653\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1654\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1655\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1656\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1657\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1658\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1660\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(outputs[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m   1661\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m lm_logits \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_logits_bias\u001b[38;5;241m.\u001b[39mto(lm_logits\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[1;32mc:\\Users\\vishn\\OneDrive\\Desktop\\GUI\\creategui\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vishn\\OneDrive\\Desktop\\GUI\\creategui\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\vishn\\OneDrive\\Desktop\\GUI\\creategui\\Lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:1528\u001b[0m, in \u001b[0;36mBartModel.forward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1521\u001b[0m     encoder_outputs \u001b[38;5;241m=\u001b[39m BaseModelOutput(\n\u001b[0;32m   1522\u001b[0m         last_hidden_state\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m   1523\u001b[0m         hidden_states\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1524\u001b[0m         attentions\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1525\u001b[0m     )\n\u001b[0;32m   1527\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[1;32m-> 1528\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1530\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1531\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1532\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1534\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1536\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1537\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1538\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1539\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1540\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1541\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n\u001b[0;32m   1544\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m decoder_outputs \u001b[38;5;241m+\u001b[39m encoder_outputs\n",
      "File \u001b[1;32mc:\\Users\\vishn\\OneDrive\\Desktop\\GUI\\creategui\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vishn\\OneDrive\\Desktop\\GUI\\creategui\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\vishn\\OneDrive\\Desktop\\GUI\\creategui\\Lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:1380\u001b[0m, in \u001b[0;36mBartDecoder.forward\u001b[1;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1367\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m   1368\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m   1369\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1377\u001b[0m         use_cache,\n\u001b[0;32m   1378\u001b[0m     )\n\u001b[0;32m   1379\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1380\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1381\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1384\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1387\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[0;32m   1388\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1389\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1390\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1391\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1392\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1393\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mc:\\Users\\vishn\\OneDrive\\Desktop\\GUI\\creategui\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vishn\\OneDrive\\Desktop\\GUI\\creategui\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\vishn\\OneDrive\\Desktop\\GUI\\creategui\\Lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:666\u001b[0m, in \u001b[0;36mBartDecoderLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[0;32m    664\u001b[0m self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    665\u001b[0m \u001b[38;5;66;03m# add present self-attn cache to positions 1,2 of present_key_value tuple\u001b[39;00m\n\u001b[1;32m--> 666\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    673\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mdropout(hidden_states, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[0;32m    674\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n",
      "File \u001b[1;32mc:\\Users\\vishn\\OneDrive\\Desktop\\GUI\\creategui\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vishn\\OneDrive\\Desktop\\GUI\\creategui\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\vishn\\OneDrive\\Desktop\\GUI\\creategui\\Lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:475\u001b[0m, in \u001b[0;36mBartSdpaAttention.forward\u001b[1;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[0;32m    472\u001b[0m     value_states \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([past_key_value[\u001b[38;5;241m1\u001b[39m], value_states], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    473\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    474\u001b[0m     \u001b[38;5;66;03m# self_attention\u001b[39;00m\n\u001b[1;32m--> 475\u001b[0m     key_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, bsz)\n\u001b[0;32m    476\u001b[0m     value_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_proj(hidden_states), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, bsz)\n\u001b[0;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_decoder:\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;66;03m# if cross_attention save Tuple(torch.Tensor, torch.Tensor) of all cross attention key/value_states.\u001b[39;00m\n\u001b[0;32m    480\u001b[0m     \u001b[38;5;66;03m# Further calls to cross_attention layer can then reuse all cross-attention\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[38;5;66;03m# can concat previous decoder key/value_states to current projected key/value_states (third \"elif\" case)\u001b[39;00m\n\u001b[0;32m    485\u001b[0m     \u001b[38;5;66;03m# if encoder bi-directional self-attention `past_key_value` is always `None`\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\vishn\\OneDrive\\Desktop\\GUI\\creategui\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vishn\\OneDrive\\Desktop\\GUI\\creategui\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\vishn\\OneDrive\\Desktop\\GUI\\creategui\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train(resume_from_checkpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-21T10:55:36.457249Z",
     "iopub.status.busy": "2024-08-21T10:55:36.456717Z",
     "iopub.status.idle": "2024-08-21T10:55:36.464456Z",
     "shell.execute_reply": "2024-08-21T10:55:36.463223Z",
     "shell.execute_reply.started": "2024-08-21T10:55:36.457213Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50264\n"
     ]
    }
   ],
   "source": [
    "print(model.config.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-21T10:56:58.937772Z",
     "iopub.status.busy": "2024-08-21T10:56:58.936484Z",
     "iopub.status.idle": "2024-08-21T10:56:58.958957Z",
     "shell.execute_reply": "2024-08-21T10:56:58.957625Z",
     "shell.execute_reply.started": "2024-08-21T10:56:58.937726Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs: tensor([[    0, 31414,     6,   141,    32,    47,   116,     2]])\n",
      "Vocab Size: 50265\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Tokenize a sample input\n",
    "inputs = tokenizer(\"Hello, how are you?\", return_tensors=\"pt\")\n",
    "print(\"Input IDs:\", inputs['input_ids'])\n",
    "\n",
    "# Check token IDs range\n",
    "vocab_size = tokenizer.vocab_size\n",
    "print(\"Vocab Size:\", vocab_size)\n",
    "if (inputs['input_ids'] >= vocab_size).any():\n",
    "    raise ValueError(\"Some token IDs are out of range\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "creategui",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
