{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install transformers datasets","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-19T10:31:26.213511Z","iopub.execute_input":"2024-11-19T10:31:26.214106Z","iopub.status.idle":"2024-11-19T10:31:39.339631Z","shell.execute_reply.started":"2024-11-19T10:31:26.214057Z","shell.execute_reply":"2024-11-19T10:31:39.338077Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.42.3)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.20.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.23.4)\nRequirement already satisfied: numpy<2.0,>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.5.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from datasets import load_dataset\ndataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T10:31:39.343099Z","iopub.execute_input":"2024-11-19T10:31:39.343619Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/15.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"620b9bbfc9964ffd82720036c8f945f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/257M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f04b5a0c87249df867964d1f9868b6c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/257M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed446ec6854e48568474fdcdcd89954c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/259M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d16c493897dd440d84163c2d6b042863"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/34.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"efeae54391e74d4b9d3817b6bbcb59b9"}},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n# Compute lengths\narticle_lengths = [len(article.split()) for article in dataset['train']['article']]\nsummary_lengths = [len(summary.split()) for summary in dataset['train']['highlights']]\n\n# Plotting Article Lengths\nplt.figure(figsize=(14, 6))\nsns.histplot(article_lengths, bins=50, color='blue')\nplt.title('Distribution of Article Lengths')\nplt.xlabel('Number of Words')\nplt.ylabel('Frequency')\nplt.show()\n\n# Plotting Summary Lengths\nplt.figure(figsize=(14, 6))\nsns.histplot(summary_lengths, bins=100, color='red')\nplt.title('Distribution of Summary Lengths')\nplt.xlabel('Number of Words')\nplt.ylabel('Frequency')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\n# Join all summaries\ntext = \" \".join(summary for summary in dataset['train']['highlights'])\n\n# Optionally, you can clean the text (remove stopwords, punctuation, etc.)\n# For example:\n# text = clean_text_function(text)\n\n# Generate word cloud\nwordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n\n# Plot the word cloud\nplt.figure(figsize=(10, 5))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis('off')  # Disable axis\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import BartTokenizer, BartForConditionalGeneration\n\ntokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\nmodel = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def preprocess_function(examples):\n    # Tokenize articles and highlights\n    inputs = tokenizer(examples['article'], padding='max_length', max_length=1801, truncation=True)\n    labels = tokenizer(examples['highlights'], padding='max_length', max_length=150, truncation=True)\n\n    # Ensure that labels are padded to the same length as inputs\n    inputs['labels'] = labels['input_ids']\n    return inputs\n\n# Apply the preprocessing function to the dataset\ntokenized_datasets = dataset.map(preprocess_function, batched=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import Trainer, TrainingArguments\n\n\n# Define training arguments\ntraining_args = TrainingArguments(c  \n    output_dir='./results',          \n    num_train_epochs=3,              \n    per_device_train_batch_size=4,  \n    per_device_eval_batch_size=4,   \n    warmup_steps=500,                \n    weight_decay=0.01,               \n    logging_dir='./logs',\n    report_to=\"none\",\n    remove_unused_columns=False,\n)\n\n# Initialize Trainer\ntrainer = Trainer(\n    model=model.to('cpu'),\n    args=training_args,\n    train_dataset=tokenized_datasets['train'],\n    eval_dataset=tokenized_datasets['validation'],\n)\n\n# Start training\ntrainer.train()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(model.config.vocab_size)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-21T10:55:36.456717Z","iopub.execute_input":"2024-08-21T10:55:36.457249Z","iopub.status.idle":"2024-08-21T10:55:36.464456Z","shell.execute_reply.started":"2024-08-21T10:55:36.457213Z","shell.execute_reply":"2024-08-21T10:55:36.463223Z"},"trusted":true},"outputs":[{"name":"stdout","text":"50264\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"\n# Tokenize a sample input\ninputs = tokenizer(\"Hello, how are you?\", return_tensors=\"pt\")\nprint(\"Input IDs:\", inputs['input_ids'])\n\n# Check token IDs range\nvocab_size = tokenizer.vocab_size\nprint(\"Vocab Size:\", vocab_size)\nif (inputs['input_ids'] >= vocab_size).any():\n    raise ValueError(\"Some token IDs are out of range\")","metadata":{"execution":{"iopub.status.busy":"2024-08-21T10:56:58.936484Z","iopub.execute_input":"2024-08-21T10:56:58.937772Z","iopub.status.idle":"2024-08-21T10:56:58.958957Z","shell.execute_reply.started":"2024-08-21T10:56:58.937726Z","shell.execute_reply":"2024-08-21T10:56:58.957625Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Input IDs: tensor([[    0, 31414,     6,   141,    32,    47,   116,     2]])\nVocab Size: 50265\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}